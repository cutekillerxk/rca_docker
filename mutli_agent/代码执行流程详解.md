# ä»£ç æ‰§è¡Œæµç¨‹è¯¦è§£

## ä¸€ã€ç¨‹åºå¯åŠ¨æµç¨‹

### 1.1 ç¨‹åºå…¥å£ï¼ˆ`gradio_demo.py:551-552`ï¼‰

```python
if __name__ == "__main__":
    main()
```

**å‘½ä»¤è¡Œè¾“å‡ºå¯¹åº”**ï¼š
```
(rca) [xiongkui@s1 mutli_agent]$ py gradio_demo.py
```

---

### 1.2 ä¸»å‡½æ•°æ‰§è¡Œï¼ˆ`gradio_demo.py:442-548`ï¼‰

#### æ­¥éª¤1ï¼šæ‰“å°å¯åŠ¨ä¿¡æ¯ï¼ˆ`gradio_demo.py:444-456`ï¼‰

```python
def main():
    print("=" * 60)
    print("Hadoop é›†ç¾¤ç›‘æ§ Agent - Gradio Web ç•Œé¢ (å¤šæ™ºèƒ½ä½“æ¡†æ¶)")
    print("=" * 60)
    # ...
```

**å‘½ä»¤è¡Œè¾“å‡ºå¯¹åº”**ï¼š
```
============================================================
Hadoop é›†ç¾¤ç›‘æ§ Agent - Gradio Web ç•Œé¢ (å¤šæ™ºèƒ½ä½“æ¡†æ¶)
============================================================

[INFO] ä½¿ç”¨å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼ˆåˆ†ç±»â†’ä¸“å®¶â†’è®¨è®ºï¼‰
[INFO] æ¨¡å¼: vLLMï¼ˆQwen3-8Bï¼‰
```

#### æ­¥éª¤2ï¼šé¢„åŠ è½½Orchestratorï¼ˆ`gradio_demo.py:458-478`ï¼‰

```python
print("[INFO] æ­£åœ¨é¢„åŠ è½½ Orchestrator...")
try:
    init_orchestrator("qwen-8b")  # è°ƒç”¨åˆå§‹åŒ–å‡½æ•°
    print("[INFO] Orchestrator é¢„åŠ è½½å®Œæˆï¼ˆé»˜è®¤æ¨¡å‹: Qwen-8Bï¼‰ï¼")
except Exception as e:
    # é”™è¯¯å¤„ç†
``` 

**æ‰§è¡Œé€»è¾‘**ï¼š
1. è°ƒç”¨ `init_orchestrator("qwen-8b")`ï¼ˆ`gradio_demo.py:47-90`ï¼‰
2. åˆ›å»º `LLMClient` å®ä¾‹ï¼ˆ`llm_client.py:34-100`ï¼‰
3. åˆ›å»º `FaultOrchestrator` å®ä¾‹ï¼ˆ`orchestrator.py:30-91`ï¼‰
4. åˆå§‹åŒ–æ‰€æœ‰Agentï¼ˆåˆ†ç±»Agentã€è®¨è®ºAgentã€ä¸“å®¶Agentï¼‰

**å‘½ä»¤è¡Œè¾“å‡ºå¯¹åº”**ï¼š
```
[INFO] æ­£åœ¨é¢„åŠ è½½ Orchestrator...
[æç¤º] è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...
------------------------------------------------------------
[INFO] Orchestratoræœªåˆå§‹åŒ–ï¼Œæ­£åœ¨åˆ›å»ºï¼ˆæ¨¡å‹: Qwen-8B (vLLM)ï¼‰...
[LLMClient] åˆå§‹åŒ–å®Œæˆ - æ¨¡å‹: qwen-8b, base_url: http://10.157.197.76:8001/v1
[LLMClient] APIè°ƒç”¨æ—¶å°†ä½¿ç”¨çš„æ¨¡å‹æ ‡è¯†ç¬¦: /media/hnu/LLM/hnu/LLM/Qwen3-8B
ç”Ÿæˆç³»ç»Ÿæç¤ºè¯  # æ¯ä¸ªAgentåˆå§‹åŒ–æ—¶éƒ½ä¼šç”Ÿæˆç³»ç»Ÿæç¤ºè¯
ç”Ÿæˆç³»ç»Ÿæç¤ºè¯
ç”Ÿæˆç³»ç»Ÿæç¤ºè¯
ç”Ÿæˆç³»ç»Ÿæç¤ºè¯
ç”Ÿæˆç³»ç»Ÿæç¤ºè¯
ç”Ÿæˆç³»ç»Ÿæç¤ºè¯
[INFO] âœ… å¤šæ™ºèƒ½ä½“åè°ƒå™¨åˆå§‹åŒ–å®Œæˆï¼ˆæ¨¡å‹: Qwen-8B (vLLM)ï¼‰
[INFO] Orchestrator é¢„åŠ è½½å®Œæˆï¼ˆé»˜è®¤æ¨¡å‹: Qwen-8Bï¼‰ï¼
```

#### æ­¥éª¤3ï¼šåˆ›å»ºGradioç•Œé¢ï¼ˆ`gradio_demo.py:519-540`ï¼‰

```python
print("[INFO] æ­£åœ¨å¯åŠ¨ Gradio ç•Œé¢...")
demo = create_gradio_interface()  # åˆ›å»ºç•Œé¢ï¼ˆgradio_demo.py:104-439ï¼‰
demo_instance = demo
demo.launch(server_name="127.0.0.1", server_port=7860, ...)
```

**æ‰§è¡Œé€»è¾‘**ï¼š
1. è°ƒç”¨ `create_gradio_interface()`ï¼ˆ`gradio_demo.py:104-439`ï¼‰
2. åˆ›å»ºGradio Blockså¸ƒå±€
3. ç»‘å®šäº‹ä»¶å¤„ç†å™¨ï¼ˆ`msg.submit`ã€`submit_btn.click`åœ¨370-371è¡Œï¼‰

**å‘½ä»¤è¡Œè¾“å‡ºå¯¹åº”**ï¼š
```
[INFO] æ­£åœ¨å¯åŠ¨ Gradio ç•Œé¢...
[INFO] ç•Œé¢å¯åŠ¨åï¼Œè¯·åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æ˜¾ç¤ºçš„ URL
------------------------------------------------------------

[DEBUG] Gradioå·¥ä½œç›®å½•: /media/hnu/hnu2025/xiongkui/rca_docker/rca-main/mutli_agent
[DEBUG] Exportsç›®å½•: /media/hnu/hnu2025/xiongkui/rca_docker/rca-main/mutli_agent/exports
* Running on local URL:  http://127.0.0.1:7860
```

---

## äºŒã€ç”¨æˆ·è¾“å…¥å¤„ç†æµç¨‹

### 2.1 ç”¨æˆ·è¾“å…¥ï¼ˆæµè§ˆå™¨ç•Œé¢ï¼‰

ç”¨æˆ·åœ¨Gradioç•Œé¢çš„è¾“å…¥æ¡†ä¸­è¾“å…¥ï¼š"æŸ¥çœ‹é›†ç¾¤æ—¥å¿—ï¼Œåˆ†æé›†ç¾¤æ•…éšœ"ï¼Œç„¶åç‚¹å‡»"å‘é€"æŒ‰é’®æˆ–æŒ‰Enteré”®ã€‚

---

### 2.2 å‰ç«¯æ¥æ”¶ç”¨æˆ·è¾“å…¥ï¼ˆ`gradio_demo.py:370-371`ï¼‰

```python
msg.submit(respond, [msg, chatbot, model_selector], [chatbot, msg])
submit_btn.click(respond, [msg, chatbot, model_selector], [chatbot, msg])
```

**æ‰§è¡Œé€»è¾‘**ï¼š
- Gradioæ¡†æ¶è‡ªåŠ¨æ•è·ç”¨æˆ·è¾“å…¥
- å°†è¾“å…¥ä¼ é€’ç»™ `respond` å‡½æ•°
- å‚æ•°ï¼š`message`ï¼ˆç”¨æˆ·è¾“å…¥ï¼‰ã€`chat_history`ï¼ˆå¯¹è¯å†å²ï¼‰ã€`selected_model`ï¼ˆé€‰æ‹©çš„æ¨¡å‹ï¼‰

---

### 2.3 å“åº”å‡½æ•°å¤„ç†ï¼ˆ`gradio_demo.py:260-336`ï¼‰

**æ³¨æ„**ï¼š`respond`å‡½æ•°å®šä¹‰åœ¨`create_gradio_interface()`å‡½æ•°å†…éƒ¨ï¼ˆ260-336è¡Œï¼‰ï¼Œäº‹ä»¶ç»‘å®šåœ¨370-371è¡Œã€‚

#### æ­¥éª¤1ï¼šç«‹å³æ˜¾ç¤º"æ­£åœ¨å¤„ç†"ï¼ˆ`gradio_demo.py:267-269`ï¼‰

```python
def respond(message, chat_history, selected_model):
    if not message.strip():
        return chat_history, ""
    
    # ç¬¬ä¸€æ­¥ï¼šç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯ï¼Œå¹¶æ˜¾ç¤º"æ­£åœ¨å¤„ç†..."æç¤º
    chat_history.append([message, "â³ æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™..."])
    yield chat_history, ""  # ä½¿ç”¨yieldå®ç°æµå¼æ›´æ–°
```

**æ‰§è¡Œé€»è¾‘**ï¼š
- å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°å¯¹è¯å†å²
- ç«‹å³æ˜¾ç¤º"æ­£åœ¨å¤„ç†..."æç¤º
- ä½¿ç”¨ `yield` å®ç°å¼‚æ­¥æ›´æ–°ç•Œé¢

---

#### æ­¥éª¤2ï¼šéªŒè¯æ¨¡å‹é€‰æ‹©ï¼ˆ`gradio_demo.py:273-285`ï¼‰

```python
# æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦åœ¨æ˜ å°„ä¸­
if selected_model not in MODEL_NAME_MAP:
    error_msg = f"âŒ æœªçŸ¥çš„æ¨¡å‹é€‰æ‹©: {selected_model}ï¼Œè¯·é€‰æ‹©æœ‰æ•ˆçš„æ¨¡å‹"
    # é”™è¯¯å¤„ç†...
    yield chat_history, ""
    return

model_name = MODEL_NAME_MAP[selected_model]  # "Qwen-8B (vLLM)" -> "qwen-8b"
```

**å‘½ä»¤è¡Œè¾“å‡ºå¯¹åº”**ï¼š
```
[DEBUG] ========== å¤„ç†ç”¨æˆ·æ¶ˆæ¯ ==========
[DEBUG] ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹: Qwen-8B (vLLM) -> qwen-8b
```

---

#### æ­¥éª¤3ï¼šè·å–Orchestratorï¼ˆ`gradio_demo.py:290-292`ï¼‰

```python
print(f"[DEBUG] è°ƒç”¨ init_orchestrator('{model_name}') è·å–åè°ƒå™¨...")
current_orchestrator = init_orchestrator(model_name)
print(f"[DEBUG] âœ… åè°ƒå™¨è·å–æˆåŠŸï¼Œå¼€å§‹è¯Šæ–­...")
```

**æ‰§è¡Œé€»è¾‘**ï¼š
1. è°ƒç”¨ `init_orchestrator(model_name)`ï¼ˆ`gradio_demo.py:47-90`ï¼‰
2. å¦‚æœOrchestratorå·²å­˜åœ¨ä¸”æ¨¡å‹ç›¸åŒï¼Œç›´æ¥è¿”å›ï¼ˆ`gradio_demo.py:87-88`ï¼‰
3. å¦‚æœæ¨¡å‹ä¸åŒæˆ–æœªåˆå§‹åŒ–ï¼Œé‡æ–°åˆ›å»º

**å‘½ä»¤è¡Œè¾“å‡ºå¯¹åº”**ï¼š
```
[DEBUG] è°ƒç”¨ init_orchestrator('qwen-8b') è·å–åè°ƒå™¨...
[DEBUG] ä½¿ç”¨ç°æœ‰Orchestratorï¼ˆæ¨¡å‹: Qwen-8B (vLLM)ï¼‰
[DEBUG] âœ… åè°ƒå™¨è·å–æˆåŠŸï¼Œå¼€å§‹è¯Šæ–­...
```

---

#### æ­¥éª¤4ï¼šæ‰§è¡Œè¯Šæ–­ï¼ˆ`gradio_demo.py:295`ï¼‰

```python
# æ‰§è¡Œè¯Šæ–­ï¼ˆè¿”å›å¯¹è¯å¼æ–‡æœ¬ï¼‰
response = current_orchestrator.diagnose(message)
```

**æ‰§è¡Œé€»è¾‘**ï¼š
- è°ƒç”¨ `FaultOrchestrator.diagnose()`ï¼ˆ`orchestrator.py:202-224`ï¼‰

---

## ä¸‰ã€Orchestratorè¯Šæ–­æµç¨‹

### 3.1 è¯Šæ–­å…¥å£ï¼ˆ`orchestrator.py:202-224`ï¼‰

```python
def diagnose(self, user_input: str, output_format: str = "text") -> Any:
    report = self._diagnose_structured(user_input)  # æ‰§è¡Œç»“æ„åŒ–è¯Šæ–­
    
    if output_format == "structured":
        return report
    
    # é»˜è®¤è¿”å›æ–‡æœ¬è¾“å‡ºï¼ˆå¯¹è¯å¼ï¼‰
    from .utils.response_formatter import ResponseFormatter
    formatted_text = ResponseFormatter.format_diagnosis_report(report)
    
    # ä¿å­˜å“åº”åˆ° return ç›®å½•
    self._save_response(user_input, formatted_text)
    
    return formatted_text
```

---

### 3.2 ç»“æ„åŒ–è¯Šæ–­æµç¨‹ï¼ˆ`orchestrator.py:226-303`ï¼‰

#### æ­¥éª¤1ï¼šæ”¶é›†å…¨å±€ä¸Šä¸‹æ–‡ï¼ˆ`orchestrator.py:232-234`ï¼‰

```python
print("\n[æ­¥éª¤1] æ”¶é›†å…¨å±€ä¸Šä¸‹æ–‡...")
global_context = self._collect_global_context()
```

**æ‰§è¡Œé€»è¾‘**ï¼š
1. è°ƒç”¨ `_collect_global_context()`ï¼ˆ`orchestrator.py:92-102`ï¼‰
2. è°ƒç”¨ `ContextCollector.collect_all_context()`ï¼ˆ`context_collector.py:29-118`ï¼‰

**è¯¦ç»†æ‰§è¡Œ**ï¼ˆ`context_collector.py:49-100`ï¼‰ï¼š
```python
# 1. æ”¶é›†æ—¥å¿—
all_logs, new_positions, new_files = read_all_cluster_logs(...)
save_log_reader_state(new_positions, new_files)
context["logs"] = all_logs

# ä¿å­˜æ—¥å¿—åˆ° result ç›®å½•
result_dir = os.path.join(rca_dir, "result")
# ... ä¿å­˜æ—¥å¿—æ–‡ä»¶

# 2. æ”¶é›†ç›‘æ§æŒ‡æ ‡
metrics = collect_all_metrics()
context["metrics"] = metrics

# 3. æå–é›†ç¾¤çŠ¶æ€
cluster_state = self._extract_cluster_state(context["metrics"])
context["cluster_state"] = cluster_state
```

**å‘½ä»¤è¡Œè¾“å‡ºå¯¹åº”**ï¼š
```
======================================================================
[Orchestrator] å¼€å§‹è¯Šæ–­æµç¨‹
======================================================================

[æ­¥éª¤1] æ”¶é›†å…¨å±€ä¸Šä¸‹æ–‡...
[Orchestrator] æ”¶é›†å…¨å±€ä¸Šä¸‹æ–‡...
ä»æ–‡ä»¶åŠ è½½æ—¥å¿—è¯»å–å™¨çš„çŠ¶æ€
è¯»å–æ‰€æœ‰5ä¸ªèŠ‚ç‚¹çš„æ—¥å¿—
åˆå§‹åŒ– Docker è¯»å–å™¨
é€šè¿‡ Docker è¯»å–å®¹å™¨æ—¥å¿—: namenode
é€šè¿‡ Docker è¯»å–å®¹å™¨æ—¥å¿—: namenode
é€šè¿‡ Docker è¯»å–å®¹å™¨æ—¥å¿—: namenode
é€šè¿‡ Docker è¯»å–å®¹å™¨æ—¥å¿—: datanode1
é€šè¿‡ Docker è¯»å–å®¹å™¨æ—¥å¿—: datanode2
é€šè¿‡ Docker è¯»å–å®¹å™¨æ—¥å¿—: namenode
é€šè¿‡ Docker è¯»å–å®¹å™¨æ—¥å¿—: namenode
é€šè¿‡ Docker è¯»å–å®¹å™¨æ—¥å¿—: datanode1
é€šè¿‡ Docker è¯»å–å®¹å™¨æ—¥å¿—: datanode2
é€šè¿‡ Docker è¯»å–å®¹å™¨æ—¥å¿—: namenode
ä¿å­˜æ—¥å¿—è¯»å–å™¨çš„çŠ¶æ€åˆ°æ–‡ä»¶
[ContextCollector] é›†ç¾¤æ—¥å¿—å·²ä¿å­˜åˆ°: /media/hnu/hnu2025/xiongkui/rca_docker/rca-main/result/cluster_logs_20260129_194609.txt
[Orchestrator] å…¨å±€ä¸Šä¸‹æ–‡æ”¶é›†å®Œæˆï¼ˆæ—¥å¿—èŠ‚ç‚¹æ•°: 10ï¼‰
```

**è¿”å›çš„å…¨å±€ä¸Šä¸‹æ–‡ç»“æ„**ï¼š
```python
{
    "timestamp": "2026-01-29T19:46:09",
    "logs": {
        "NameNode": "...",
        "DataNode1": "...",
        "DataNode2": "...",
        ...
    },
    "metrics": {
        "namenode": {...},
        "datanodes": {...},
        "resourcemanager": {...},
        "nodemanagers": {...}
    },
    "cluster_state": {
        "datanode_count": {"live": 0, "dead": 0, "total": 0},
        "hdfs_status": "unknown",
        "storage": {...}
    }
}
```

---

#### æ­¥éª¤2ï¼šæ•…éšœåˆ†ç±»ï¼ˆ`orchestrator.py:236-243`ï¼‰

```python
print("\n[æ­¥éª¤2] æ•…éšœåˆ†ç±»...")
classification_input = {
    "logs": global_context.get("logs", {}),
    "metrics": global_context.get("metrics", {}),
    "user_query": user_input,
}
classification_result = self.classifier.run(classification_input)
```

**æ‰§è¡Œé€»è¾‘**ï¼š
1. æ„å»ºåˆ†ç±»è¾“å…¥æ•°æ®ï¼ˆåŒ…å«æ—¥å¿—ã€ç›‘æ§æŒ‡æ ‡ã€ç”¨æˆ·æŸ¥è¯¢ï¼‰
2. è°ƒç”¨ `FaultClassifierAgent.run()`ï¼ˆ`base.py:93-145`ï¼‰

**åˆ†ç±»Agentæ‰§è¡Œæµç¨‹**ï¼ˆ`base.py:106-116`ï¼‰ï¼š
```python
# 1. æ„å»ºprompt
prompt = self.build_prompt(current_input)  # classifier.py:76-125

# 2. è°ƒç”¨LLMï¼ˆä½¿ç”¨Role Tokenï¼‰
response = self.llm_client.generate_with_role(
    role="classifier",
    prompt=prompt,
    system_prompt=self.system_prompt,
    temperature=0
)

# 3. è§£æè¾“å‡º
parsed = self.parse_output(response)  # classifier.py:127-196
```

**LLMè°ƒç”¨æµç¨‹**ï¼ˆ`llm_client.py:142-167`ï¼‰ï¼š
```python
def generate_with_role(self, role, prompt, system_prompt, temperature):
    role_token = f"<ROLE={role}>"  # "<ROLE=classifier>"
    return self.generate(
        prompt=prompt,
        system_prompt=system_prompt,
        temperature=temperature,
        role_token=role_token
    )
```

**APIè°ƒç”¨**ï¼ˆ`llm_client.py:242-280`ï¼‰ï¼š
```python
def _call_api(self, messages, temperature):
    url = f"{self.base_url}/chat/completions"  # http://10.157.197.76:8001/v1/chat/completions
    payload = {
        "model": self.model,  # "/media/hnu/LLM/hnu/LLM/Qwen3-8B"
        "messages": messages,
        "temperature": temperature,
        "max_tokens": self.max_tokens,
    }
    response = requests.post(url, headers=headers, json=payload, timeout=self.timeout)
    # æå–ç”Ÿæˆçš„æ–‡æœ¬
    content = response.json()["choices"][0]["message"]["content"]
    return content
```

**å‘½ä»¤è¡Œè¾“å‡ºå¯¹åº”**ï¼š
```
[æ­¥éª¤2] æ•…éšœåˆ†ç±»...
[DEBUG] APIè¯·æ±‚URL: http://10.157.197.76:8001/v1/chat/completions
[DEBUG] APIè¯·æ±‚æ¨¡å‹: /media/hnu/LLM/hnu/LLM/Qwen3-8B
[DEBUG] APIè¯·æ±‚payload: {
  "model": "/media/hnu/LLM/hnu/LLM/Qwen3-8B",
  "messages": [
    {
      "role": "system",
      "content": "ä½ æ˜¯æ•…éšœåˆ†ç±»ä¸“å®¶ï¼Œè´Ÿè´£åˆ†æHadoopé›†ç¾¤æ—¥å¿—å’Œç›‘æ§æŒ‡æ ‡ï¼Œè¯†åˆ«æ•…éšœç±»å‹ã€‚\n\n## ä½ çš„ä»»åŠ¡\n1. åˆ†ææä¾›çš„æ—¥å¿—å’Œç›‘æ§æŒ‡æ ‡\n2. è¯†åˆ«æ•…éšœç±»å‹ï¼ˆä»å·²çŸ¥æ•…éšœç±»å‹åº“ä¸­é€‰æ‹©ï¼‰\n3. è¾“å‡ºJSONæ ¼å¼çš„åˆ†ç±»ç»“æœ\n\n## å·²çŸ¥æ•…éšœç±»å‹åº“\n- datanode_down: DataNodeä¸‹çº¿ (hdfs)\n- namenode_safemode: NameNodeå®‰å…¨æ¨¡å¼ (hdfs)\n- cluster_id_mismatch: é›†ç¾¤IDä¸åŒ¹é… (hdfs)\n- resourcemanager_down: ResourceManagerä¸‹çº¿ (yarn)\n- nodemanager_down: NodeManagerä¸‹çº¿ (yarn)\n- yarn_config_error: YARNé…ç½®é”™è¯¯ (yarn)\n- mapreduce_memory_...
[Orchestrator] åˆ†ç±»ç»“æœ: none (ç½®ä¿¡åº¦: 0.5)
```

**åˆ†ç±»ç»“æœè§£æ**ï¼ˆ`classifier.py:127-196`ï¼‰ï¼š
```python
def parse_output(self, response: str):
    # ç§»é™¤markdownä»£ç å—æ ‡è®°
    response = response.strip()
    if response.startswith("```json"):
        response = response[7:]
    # è§£æJSON
    result_dict = json.loads(response)
    # åˆ›å»ºClassificationResultå¯¹è±¡
    classification = ClassificationResult(...)
    return classification.to_dict()
```

**è¿”å›çš„åˆ†ç±»ç»“æœ**ï¼š
```python
{
    "fault_type": "none",  # æˆ– "datanode_down" ç­‰
    "confidence": 0.5,
    "category": "generic",
    "related_faults": None,
    "reasoning": "..."
}
```

---

#### æ­¥éª¤3ï¼šé€‰æ‹©ç›¸å…³ä¸“å®¶ï¼ˆ`orchestrator.py:248-250`ï¼‰

```python
print("\n[æ­¥éª¤3] é€‰æ‹©ç›¸å…³ä¸“å®¶...")
expert_names = self._select_relevant_experts(fault_type, include_related=True)
```

**æ‰§è¡Œé€»è¾‘**ï¼ˆ`orchestrator.py:104-124`ï¼‰ï¼š
```python
def _select_relevant_experts(self, fault_type, include_related=True):
    experts = self.expert_selector.select_experts(
        fault_type=fault_type,
        include_related=include_related
    )
    print(f"[Orchestrator] é€‰æ‹©ä¸“å®¶: {experts}")
    return experts
```

**ä¸“å®¶é€‰æ‹©é€»è¾‘**ï¼ˆ`expert_selector.py:78-104`ï¼‰ï¼š
```python
def select_experts(self, fault_type, include_related=True):
    if fault_type not in self.fault_expert_mapping:
        return ["generic_expert"]  # æœªçŸ¥æ•…éšœç±»å‹ï¼Œè¿”å›é€šç”¨ä¸“å®¶
    
    mapping = self.fault_expert_mapping[fault_type]
    experts = mapping["primary"].copy()  # ä¸»è¦ä¸“å®¶
    
    if include_related:
        experts.extend(mapping["related"])  # ç›¸å…³ä¸“å®¶
    
    return list(dict.fromkeys(experts))  # å»é‡
```

**å‘½ä»¤è¡Œè¾“å‡ºå¯¹åº”**ï¼š
```
[æ­¥éª¤3] é€‰æ‹©ç›¸å…³ä¸“å®¶...
[Orchestrator] é€‰æ‹©ä¸“å®¶: ['generic_expert']
```

---

#### æ­¥éª¤4ï¼šå¹¶è¡Œè°ƒç”¨ä¸“å®¶ï¼ˆ`orchestrator.py:252-262`ï¼‰

```python
print(f"\n[æ­¥éª¤4] å¹¶è¡Œè°ƒç”¨ {len(expert_names)} ä¸ªä¸“å®¶...")
expert_input = {
    "fault_type": fault_type,
    "logs": global_context.get("logs", {}),
    "metrics": global_context.get("metrics", {}),
    "cluster_state": global_context.get("cluster_state", {}),
    "related_faults": classification_result.get("related_faults"),
    "user_query": user_input,
}
expert_results = self._call_experts_parallel(expert_names, expert_input)
```

**æ‰§è¡Œé€»è¾‘**ï¼ˆ`orchestrator.py:164-200`ï¼‰ï¼š
```python
def _call_experts_parallel(self, expert_names, input_data):
    results = []
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œè°ƒç”¨
    with ThreadPoolExecutor(max_workers=len(expert_names)) as executor:
        futures = {
            executor.submit(self._call_expert, expert_name, input_data): expert_name
            for expert_name in expert_names
        }
        
        for future in as_completed(futures):
            expert_name = futures[future]
            try:
                result = future.result()
                results.append(result)
            except Exception as e:
                # é”™è¯¯å¤„ç†
                results.append({"expert_name": expert_name, "error": str(e)})
    
    return results
```

**å•ä¸ªä¸“å®¶è°ƒç”¨**ï¼ˆ`orchestrator.py:126-162`ï¼‰ï¼š
```python
def _call_expert(self, expert_name, input_data):
    expert = self.experts[expert_name]  # è·å–ä¸“å®¶Agentå®ä¾‹
    print(f"[Orchestrator] è°ƒç”¨ä¸“å®¶: {expert_name}")
    result = expert.run(input_data)  # æ‰§è¡Œä¸“å®¶è¯Šæ–­
    result["expert_name"] = expert_name
    print(f"[Orchestrator] ä¸“å®¶ {expert_name} è¯Šæ–­å®Œæˆ")
    return result
```

**ä¸“å®¶Agentæ‰§è¡Œæµç¨‹**ï¼ˆ`base.py:106-145`ï¼‰ï¼š
```python
# 1. æ„å»ºpromptï¼ˆä¸“å®¶ç‰¹å®šçš„promptæ„å»ºé€»è¾‘ï¼‰
prompt = self.build_prompt(current_input)  # ä¾‹å¦‚ï¼šhdfs_expert.py:93-185

# 2. è°ƒç”¨LLMï¼ˆä½¿ç”¨Role Tokenï¼‰
response = self.llm_client.generate_with_role(
    role="hdfs_expert",  # æˆ– "generic_expert" ç­‰
    prompt=prompt,
    system_prompt=self.system_prompt,
    temperature=0
)

# 3. è§£æè¾“å‡ºï¼ˆä¸“å®¶ç‰¹å®šçš„è§£æé€»è¾‘ï¼‰
parsed = self.parse_output(response)  # ä¾‹å¦‚ï¼šhdfs_expert.py:187-311

# 4. å·¥å…·è°ƒç”¨å¾ªç¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
if parsed.get("action") == "call_tool":
    tool_result = self._execute_tool(tool_name, tool_args)
    # å°†å·¥å…·ç»“æœå†™å›ä¸Šä¸‹æ–‡ï¼Œç»§ç»­ä¸‹ä¸€è½®
    continue

return parsed
```

**å‘½ä»¤è¡Œè¾“å‡ºå¯¹åº”**ï¼š
```
[æ­¥éª¤4] å¹¶è¡Œè°ƒç”¨ 1 ä¸ªä¸“å®¶...
[Orchestrator] è°ƒç”¨ä¸“å®¶: generic_expert
[DEBUG] APIè¯·æ±‚URL: http://10.157.197.76:8001/v1/chat/completions
[DEBUG] APIè¯·æ±‚æ¨¡å‹: /media/hnu/LLM/hnu/LLM/Qwen3-8B
[DEBUG] APIè¯·æ±‚payload: {
  "model": "/media/hnu/LLM/hnu/LLM/Qwen3-8B",
  "messages": [
    {
      "role": "system",
      "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åˆ†å¸ƒå¼ç³»ç»Ÿè¿ç»´ä¸“å®¶ï¼Œä¸“æ³¨äº Hadoop/HDFS é›†ç¾¤çš„æ•…éšœè¯Šæ–­ã€‚\n\n## å½“å‰é›†ç¾¤ç¯å¢ƒ\n\n### éƒ¨ç½²æ¶æ„\n- éƒ¨ç½²æ–¹å¼ï¼šDocker Compose å®¹å™¨åŒ–éƒ¨ç½²\n- ç½‘ç»œï¼šæ‰€æœ‰å®¹å™¨åœ¨ `hadoop-network` ç½‘ç»œä¸­ï¼Œå¯é€šè¿‡å®¹å™¨åäº’ç›¸è®¿é—®\n- Hadoopç‰ˆæœ¬ï¼š3.3.6\n- Javaç‰ˆæœ¬ï¼šOpenJDK 11\n\n### èŠ‚ç‚¹æ¸…å•\n| å®¹å™¨å | è¿è¡Œçš„æœåŠ¡ | Web UI ç«¯å£ | è¯´æ˜ |\n|--------|-----------|-------------|------|\n| namenode | NameNode, DataNode, SecondaryNameNode | 9870 | ä¸»èŠ‚ç‚¹ |\n| datanod...
[Orchestrator] ä¸“å®¶ generic_expert è¯Šæ–­å®Œæˆ
```

**ä¸“å®¶è¯Šæ–­ç»“æœç»“æ„**ï¼š
```python
{
    "expert_name": "generic_expert",
    "diagnosis_text": "è¯Šæ–­æ–‡æœ¬...",
    "root_cause": "æ ¹æœ¬åŸå› ",
    "evidence": ["è¯æ®1", "è¯æ®2"],
    "fix_steps": ["æ­¥éª¤1", "æ­¥éª¤2"],
    "confidence": 0.8
}
```

---

#### æ­¥éª¤5ï¼šDiscussion Agentç»¼åˆï¼ˆ`orchestrator.py:278-285`ï¼‰

```python
print(f"\n[æ­¥éª¤5] Discussion Agentç»¼åˆ {len(valid_expert_results)} ä¸ªä¸“å®¶çš„è¯Šæ–­ç»“æœ...")
discussion_input = {
    "fault_type": fault_type,
    "expert_results": valid_expert_results,
    "global_context": global_context,
}
discussion_result = self.discussion_agent.run(discussion_input)
```

**æ‰§è¡Œé€»è¾‘**ï¼š
1. æ„å»ºè®¨è®ºè¾“å…¥ï¼ˆåŒ…å«æ•…éšœç±»å‹ã€ä¸“å®¶ç»“æœã€å…¨å±€ä¸Šä¸‹æ–‡ï¼‰
2. è°ƒç”¨ `DiscussionAgent.run()`ï¼ˆ`base.py:93-145`ï¼‰
3. Discussion Agentæ„å»ºpromptï¼Œè°ƒç”¨LLMï¼Œè§£æè¾“å‡º

**å‘½ä»¤è¡Œè¾“å‡ºå¯¹åº”**ï¼š
```
[æ­¥éª¤5] Discussion Agentç»¼åˆ 1 ä¸ªä¸“å®¶çš„è¯Šæ–­ç»“æœ...
[DEBUG] APIè¯·æ±‚URL: http://10.157.197.76:8001/v1/chat/completions
[DEBUG] APIè¯·æ±‚æ¨¡å‹: /media/hnu/LLM/hnu/LLM/Qwen3-8B
[DEBUG] APIè¯·æ±‚payload: {
  "model": "/media/hnu/LLM/hnu/LLM/Qwen3-8B",
  "messages": [
    {
      "role": "system",
      "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åˆ†å¸ƒå¼ç³»ç»Ÿè¿ç»´ä¸“å®¶ï¼Œä¸“æ³¨äº Hadoop/HDFS é›†ç¾¤çš„æ•…éšœè¯Šæ–­ã€‚\n\n## å½“å‰é›†ç¾¤ç¯å¢ƒ\n\n### éƒ¨ç½²æ¶æ„\n- éƒ¨ç½²æ–¹å¼ï¼šDocker Compose å®¹å™¨åŒ–éƒ¨ç½²\n- ç½‘ç»œï¼šæ‰€æœ‰å®¹å™¨åœ¨ `hadoop-network` ç½‘ç»œä¸­ï¼Œå¯é€šè¿‡å®¹å™¨åäº’ç›¸è®¿é—®\n- Hadoopç‰ˆæœ¬ï¼š3.3.6\n- Javaç‰ˆæœ¬ï¼šOpenJDK 11\n\n### èŠ‚ç‚¹æ¸…å•\n| å®¹å™¨å | è¿è¡Œçš„æœåŠ¡ | Web UI ç«¯å£ | è¯´æ˜ |\n|--------|-----------|-------------|------|\n| namenode | NameNode, DataNode, SecondaryNameNode | 9870 | ä¸»èŠ‚ç‚¹ |\n| datanod...
```

**è®¨è®ºç»“æœç»“æ„**ï¼š
```python
{
    "consensus": True,
    "final_root_cause": "ç»¼åˆæ ¹å› ",
    "final_evidence": ["è¯æ®1", "è¯æ®2"],
    "final_fix_steps": ["æ­¥éª¤1", "æ­¥éª¤2"],
    "confidence": 0.9,
    "conflicts": None,
    "compound_faults": None
}
```

---

#### æ­¥éª¤6ï¼šæ„å»ºè¯Šæ–­æŠ¥å‘Šï¼ˆ`orchestrator.py:287-303`ï¼‰

```python
print("\n[æ­¥éª¤6] æ„å»ºè¯Šæ–­æŠ¥å‘Š...")
report = {
    "classification": classification_result,
    "expert_diagnoses": valid_expert_results,
    "discussion": discussion_result,
    "global_context": {
        "timestamp": global_context.get("timestamp"),
        "cluster_state": global_context.get("cluster_state", {}),
    },
}
```

**å‘½ä»¤è¡Œè¾“å‡ºå¯¹åº”**ï¼š
```
[æ­¥éª¤6] æ„å»ºè¯Šæ–­æŠ¥å‘Š...

======================================================================
[Orchestrator] è¯Šæ–­æµç¨‹å®Œæˆ
======================================================================
```

---

### 3.3 æ ¼å¼åŒ–è¾“å‡ºï¼ˆ`orchestrator.py:217-224`ï¼‰

```python
# é»˜è®¤è¿”å›æ–‡æœ¬è¾“å‡ºï¼ˆå¯¹è¯å¼ï¼‰
from .utils.response_formatter import ResponseFormatter
formatted_text = ResponseFormatter.format_diagnosis_report(report)

# ä¿å­˜å“åº”åˆ° return ç›®å½•
self._save_response(user_input, formatted_text)

return formatted_text
```

**æ ¼å¼åŒ–é€»è¾‘**ï¼ˆ`response_formatter.py:19-114`ï¼‰ï¼š
```python
def format_diagnosis_report(report):
    parts = []
    
    # 1. åˆ†ç±»ç»“æœ
    parts.append("## ğŸ“‹ æ•…éšœåˆ†ç±»ç»“æœ")
    parts.append(f"**æ•…éšœç±»å‹**ï¼š{classification.get('fault_type')}")
    # ...
    
    # 2. ä¸“å®¶è¯Šæ–­ç»“æœ
    parts.append("## ğŸ” ä¸“å®¶è¯Šæ–­è¯¦æƒ…")
    for expert_diag in report["expert_diagnoses"]:
        # ...
    
    # 3. ç»¼åˆè®¨è®ºç»“æœ
    parts.append("## ğŸ’¬ ç»¼åˆè¯Šæ–­ç»“è®º")
    # ...
    
    return "\n".join(parts)
```

**ä¿å­˜å“åº”**ï¼ˆ`orchestrator.py:317-350`ï¼‰ï¼š
```python
def _save_response(self, user_input: str, response: str):
    return_dir = os.path.join(base_dir, "return")
    os.makedirs(return_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"multi_agent_response_{timestamp}.txt"
    filepath = os.path.join(return_dir, filename)
    
    # å†™å…¥æ–‡ä»¶
    with open(filepath, "w", encoding="utf-8") as f:
        f.write("\n".join(content_lines))
    
    print(f"[Orchestrator] å“åº”å·²ä¿å­˜åˆ°: {filepath}")
```

**å‘½ä»¤è¡Œè¾“å‡ºå¯¹åº”**ï¼š
```
[Orchestrator] å“åº”å·²ä¿å­˜åˆ°: /media/hnu/hnu2025/xiongkui/rca_docker/rca-main/return/multi_agent_response_20260129_194724.txt
```

---

## å››ã€è¿”å›ç»“æœåˆ°å‰ç«¯

### 4.1 æ›´æ–°å¯¹è¯å†å²ï¼ˆ`gradio_demo.py:311-318`ï¼‰

```python
last_diagnosis_response = response

# æ›´æ–°å¯¹è¯å†å²
if len(chat_history) > 0:
    if isinstance(chat_history[-1], list) and len(chat_history[-1]) >= 2:
        chat_history[-1][1] = response  # æ›¿æ¢"æ­£åœ¨å¤„ç†..."ä¸ºå®é™…å“åº”
    else:
        chat_history[-1] = [message, response]
else:
    chat_history.append([message, response])
```

### 4.2 è¿”å›ç»“æœï¼ˆ`gradio_demo.py:335-336`ï¼‰

```python
# ç¬¬ä¸‰æ­¥ï¼šè¿”å›å®Œæ•´çš„å¯¹è¯å†å²
yield chat_history, ""
```

**æ‰§è¡Œé€»è¾‘**ï¼š
- ä½¿ç”¨ `yield` è¿”å›æ›´æ–°åçš„å¯¹è¯å†å²
- Gradioæ¡†æ¶è‡ªåŠ¨æ›´æ–°ç•Œé¢æ˜¾ç¤º
- ç”¨æˆ·å¯ä»¥çœ‹åˆ°å®Œæ•´çš„è¯Šæ–­ç»“æœ

---

## äº”ã€å®Œæ•´æ‰§è¡Œæµç¨‹å›¾

```
ç”¨æˆ·è¾“å…¥ "æŸ¥çœ‹é›†ç¾¤æ—¥å¿—ï¼Œåˆ†æé›†ç¾¤æ•…éšœ"
    â†“
Gradioç•Œé¢æ•è·è¾“å…¥ï¼ˆmsg.submit / submit_btn.clickï¼‰
    â†“
respondå‡½æ•°ï¼ˆgradio_demo.py:260ï¼‰
    â”œâ”€ æ˜¾ç¤º"æ­£åœ¨å¤„ç†..."
    â”œâ”€ éªŒè¯æ¨¡å‹é€‰æ‹©
    â”œâ”€ è·å–Orchestratorï¼ˆinit_orchestratorï¼‰
    â””â”€ è°ƒç”¨ orchestrator.diagnose(message)
        â†“
FaultOrchestrator.diagnose()ï¼ˆorchestrator.py:202ï¼‰
    â”œâ”€ _diagnose_structured(user_input)
    â”‚   â”œâ”€ [æ­¥éª¤1] æ”¶é›†å…¨å±€ä¸Šä¸‹æ–‡
    â”‚   â”‚   â””â”€ ContextCollector.collect_all_context()
    â”‚   â”‚       â”œâ”€ read_all_cluster_logs() â†’ logs
    â”‚   â”‚       â”œâ”€ collect_all_metrics() â†’ metrics
    â”‚   â”‚       â””â”€ _extract_cluster_state() â†’ cluster_state
    â”‚   â”‚
    â”‚   â”œâ”€ [æ­¥éª¤2] æ•…éšœåˆ†ç±»
    â”‚   â”‚   â””â”€ FaultClassifierAgent.run()
    â”‚   â”‚       â”œâ”€ build_prompt() â†’ prompt
    â”‚   â”‚       â”œâ”€ llm_client.generate_with_role() â†’ LLM APIè°ƒç”¨
    â”‚   â”‚       â””â”€ parse_output() â†’ classification_result
    â”‚   â”‚
    â”‚   â”œâ”€ [æ­¥éª¤3] é€‰æ‹©ç›¸å…³ä¸“å®¶
    â”‚   â”‚   â””â”€ ExpertSelector.select_experts()
    â”‚   â”‚
    â”‚   â”œâ”€ [æ­¥éª¤4] å¹¶è¡Œè°ƒç”¨ä¸“å®¶
    â”‚   â”‚   â””â”€ ThreadPoolExecutorå¹¶è¡Œæ‰§è¡Œ
    â”‚   â”‚       â””â”€ æ¯ä¸ªä¸“å®¶ï¼šExpertAgent.run()
    â”‚   â”‚           â”œâ”€ build_prompt() â†’ prompt
    â”‚   â”‚           â”œâ”€ llm_client.generate_with_role() â†’ LLM APIè°ƒç”¨
    â”‚   â”‚           â””â”€ parse_output() â†’ expert_result
    â”‚   â”‚
    â”‚   â”œâ”€ [æ­¥éª¤5] Discussion Agentç»¼åˆ
    â”‚   â”‚   â””â”€ DiscussionAgent.run()
    â”‚   â”‚       â”œâ”€ build_prompt() â†’ prompt
    â”‚   â”‚       â”œâ”€ llm_client.generate_with_role() â†’ LLM APIè°ƒç”¨
    â”‚   â”‚       â””â”€ parse_output() â†’ discussion_result
    â”‚   â”‚
    â”‚   â””â”€ [æ­¥éª¤6] æ„å»ºè¯Šæ–­æŠ¥å‘Š
    â”‚       â””â”€ æ•´åˆæ‰€æœ‰ç»“æœ â†’ report
    â”‚
    â”œâ”€ ResponseFormatter.format_diagnosis_report() â†’ formatted_text
    â””â”€ _save_response() â†’ ä¿å­˜åˆ°returnç›®å½•
        â†“
è¿”å› formatted_text åˆ° respondå‡½æ•°
    â†“
æ›´æ–° chat_history
    â†“
yield chat_history â†’ Gradioç•Œé¢æ›´æ–°æ˜¾ç¤º
```

---

## å…­ã€å…³é”®ä»£ç ä½ç½®æ€»ç»“

| æ­¥éª¤ | ä»£ç ä½ç½® | å…³é”®å‡½æ•°/ç±» |
|------|---------|------------|
| ç¨‹åºå¯åŠ¨ | `gradio_demo.py:442` | `main()` |
| é¢„åŠ è½½Orchestrator | `gradio_demo.py:464` | `init_orchestrator()` |
| åˆ›å»ºç•Œé¢ | `gradio_demo.py:104` | `create_gradio_interface()` |
| ç”¨æˆ·è¾“å…¥å¤„ç† | `gradio_demo.py:260` | `respond()` |
| è¯Šæ–­å…¥å£ | `orchestrator.py:202` | `FaultOrchestrator.diagnose()` |
| æ”¶é›†ä¸Šä¸‹æ–‡ | `context_collector.py:29` | `ContextCollector.collect_all_context()` |
| åˆ†ç±»Agent | `classifier.py:21` | `FaultClassifierAgent` |
| ä¸“å®¶Agent | `hdfs_expert.py:20` ç­‰ | `HDFSExpertAgent` ç­‰ |
| è®¨è®ºAgent | `discussion.py:20` | `DiscussionAgent` |
| LLMè°ƒç”¨ | `llm_client.py:142` | `LLMClient.generate_with_role()` |
| APIè¯·æ±‚ | `llm_client.py:227` | `LLMClient._call_api()` |
| æ ¼å¼åŒ–è¾“å‡º | `response_formatter.py:19` | `ResponseFormatter.format_diagnosis_report()` |
| ä¿å­˜å“åº” | `orchestrator.py:317` | `FaultOrchestrator._save_response()` |

---

## ä¸ƒã€æ•°æ®æµå‘å›¾

```
ç”¨æˆ·è¾“å…¥
    â†“
Gradioç•Œé¢ (gradio_demo.py)
    â†“
respondå‡½æ•°
    â†“
FaultOrchestrator.diagnose()
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å…¨å±€ä¸Šä¸‹æ–‡æ”¶é›†                        â”‚
â”‚ - logs (æ‰€æœ‰èŠ‚ç‚¹æ—¥å¿—)                 â”‚
â”‚ - metrics (JMXç›‘æ§æŒ‡æ ‡)               â”‚
â”‚ - cluster_state (é›†ç¾¤çŠ¶æ€)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ åˆ†ç±»Agent                            â”‚
â”‚ è¾“å…¥: logs + metrics + user_query    â”‚
â”‚ è¾“å‡º: fault_type + confidence        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ä¸“å®¶Agentï¼ˆå¹¶è¡Œï¼‰                    â”‚
â”‚ è¾“å…¥: fault_type + logs + metrics +  â”‚
â”‚      cluster_state + user_query     â”‚
â”‚ è¾“å‡º: root_cause + evidence +        â”‚
â”‚      fix_steps + confidence          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Discussion Agent                     â”‚
â”‚ è¾“å…¥: fault_type + expert_results +  â”‚
â”‚      global_context                  â”‚
â”‚ è¾“å‡º: final_root_cause +             â”‚
â”‚      final_evidence + final_fix_stepsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
æ ¼å¼åŒ–è¾“å‡º (ResponseFormatter)
    â†“
ä¿å­˜åˆ°returnç›®å½•
    â†“
è¿”å›ç»™Gradioç•Œé¢
    â†“
ç”¨æˆ·çœ‹åˆ°è¯Šæ–­ç»“æœ
```

---

## å…«ã€æ€»ç»“

ä»ç”¨æˆ·è¾“å…¥åˆ°æœ€ç»ˆç»“æœçš„å®Œæ•´æµç¨‹ï¼š

1. **å‰ç«¯æ¥æ”¶**ï¼šGradioæ¡†æ¶æ•è·ç”¨æˆ·è¾“å…¥
2. **è¾“å…¥å¤„ç†**ï¼š`respond`å‡½æ•°éªŒè¯å’Œå¤„ç†è¾“å…¥
3. **è·å–åè°ƒå™¨**ï¼š`init_orchestrator`è·å–æˆ–åˆ›å»ºOrchestrator
4. **æ‰§è¡Œè¯Šæ–­**ï¼š`FaultOrchestrator.diagnose`æ‰§è¡Œå®Œæ•´è¯Šæ–­æµç¨‹
5. **æ”¶é›†ä¸Šä¸‹æ–‡**ï¼š`ContextCollector`æ”¶é›†æ—¥å¿—ã€ç›‘æ§æŒ‡æ ‡ã€é›†ç¾¤çŠ¶æ€
6. **åˆ†ç±»**ï¼š`FaultClassifierAgent`è¯†åˆ«æ•…éšœç±»å‹
7. **ä¸“å®¶è¯Šæ–­**ï¼šå¤šä¸ª`ExpertAgent`å¹¶è¡Œè¯Šæ–­
8. **ç»¼åˆè®¨è®º**ï¼š`DiscussionAgent`ç»¼åˆä¸“å®¶æ„è§
9. **æ ¼å¼åŒ–è¾“å‡º**ï¼š`ResponseFormatter`æ ¼å¼åŒ–è¯Šæ–­æŠ¥å‘Š
10. **ä¿å­˜ç»“æœ**ï¼šä¿å­˜åˆ°`return`ç›®å½•
11. **è¿”å›å‰ç«¯**ï¼šæ›´æ–°Gradioç•Œé¢æ˜¾ç¤ºç»“æœ

æ¯ä¸€æ­¥éƒ½æœ‰è¯¦ç»†çš„æ—¥å¿—è¾“å‡ºï¼Œå¯ä»¥é€šè¿‡å‘½ä»¤è¡Œè¾“å‡ºæ¥è¿½è¸ªæ‰§è¡Œæµç¨‹ã€‚
