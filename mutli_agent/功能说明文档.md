# 多智能体框架功能说明文档

## 目录
1. [系统概述](#系统概述)
2. [架构设计](#架构设计)
3. [核心组件](#核心组件)
4. [工作流程](#工作流程)
5. [主要功能](#主要功能)
6. [技术特点](#技术特点)
7. [使用说明](#使用说明)
8. [配置说明](#配置说明)
9. [扩展指南](#扩展指南)

---


## 系统概述

### 1.1 项目简介

多智能体框架（Multi-Agent Framework）是一个基于大语言模型（LLM）的Hadoop集群故障诊断系统。该系统采用"分类→专家→讨论"的三阶段诊断流程，通过多个专业智能体的协作，实现对Hadoop集群故障的自动识别、深度分析和修复建议生成。

### 1.2 核心特性

- **多智能体协作**：分类Agent、专家Agent、讨论Agent协同工作
- **并行专家诊断**：多个专家Agent并行分析，提高诊断效率
- **多模型支持**：支持Qwen-8B（vLLM）、GPT-4o、DeepSeek-R1等多种大模型
- **工具集成**：集成Hadoop集群操作工具，支持日志查询、监控指标获取、命令执行等
- **Web界面**：基于Gradio的友好Web界面，支持实时监控和诊断
- **文档导出**：支持将诊断结果导出为Word或PDF格式

### 1.3 应用场景

- Hadoop集群故障自动诊断
- 集群健康状态监控
- 故障根因分析
- 修复方案生成
- 集群运维辅助决策

---

## 架构设计

### 2.1 整体架构

```
┌─────────────────────────────────────────────────────────────┐
│                      Gradio Web界面                          │
│  (gradio_demo.py)                                           │
│  - 用户交互界面                                              │
│  - 实时监控显示                                              │
│  - 诊断结果展示                                              │
│  - 文档导出功能                                              │
└──────────────────────┬──────────────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────────────┐
│              故障诊断协调器 (FaultOrchestrator)                │
│  (orchestrator.py)                                           │
│  - 管理整个诊断流程                                           │
│  - 协调各Agent协作                                           │
│  - 并行调用专家Agent                                         │
└──────────────────────┬──────────────────────────────────────┘
                       │
        ┌──────────────┼──────────────┐
        ▼              ▼              ▼
┌──────────────┐ ┌──────────────┐ ┌──────────────┐
│ 分类Agent    │ │ 专家Agent    │ │ 讨论Agent    │
│ (Classifier) │ │ (Experts)    │ │ (Discussion) │
└──────────────┘ └──────────────┘ └──────────────┘
        │              │              │
        └──────────────┼──────────────┘
                       ▼
┌─────────────────────────────────────────────────────────────┐
│                    LLM客户端 (LLMClient)                      │
│  (llm_client.py)                                             │
│  - 统一LLM调用接口                                            │
│  - 支持多模型切换                                             │
│  - Role Token注入                                             │
└──────────────────────┬──────────────────────────────────────┘
                       │
        ┌──────────────┼──────────────┐
        ▼              ▼              ▼
┌──────────────┐ ┌──────────────┐ ┌──────────────┐
│   vLLM API   │ │  OpenAI API  │ │ DeepSeek API │
│  (Qwen-8B)   │ │   (GPT-4o)   │ │ (DeepSeek-R1)│
└──────────────┘ └──────────────┘ └──────────────┘
```

### 2.2 模块划分

#### 2.2.1 核心模块
- **orchestrator.py**：总协调器，管理诊断流程
- **llm_client.py**：LLM调用封装，支持多模型
- **base.py**：Agent基类，定义统一接口
- **schemas.py**：数据结构定义

#### 2.2.2 Agent模块
- **agents/classifier.py**：分类Agent
- **agents/discussion.py**：讨论Agent
- **agents/experts/**：专家Agent集合
  - `hdfs_expert.py`：HDFS专家
  - `yarn_expert.py`：YARN专家
  - `mapreduce_expert.py`：MapReduce专家
  - `network_expert.py`：网络专家
  - `generic_expert.py`：通用专家

#### 2.2.3 工具模块
- **utils/context_collector.py**：上下文收集器
- **utils/expert_selector.py**：专家选择器
- **utils/tool_adapter.py**：工具适配器
- **utils/response_formatter.py**：响应格式化器

#### 2.2.4 界面模块
- **gradio_demo.py**：Gradio Web界面

---

## 核心组件

### 3.1 故障诊断协调器 (FaultOrchestrator)

**文件位置**：`orchestrator.py`

**功能**：
- 管理整个诊断流程的六个步骤
- 协调各Agent之间的协作
- 并行调用多个专家Agent
- 构建完整的诊断报告

**主要方法**：
- `diagnose(user_input, output_format)`：执行完整诊断流程
- `_collect_global_context()`：收集全局上下文
- `_select_relevant_experts()`：选择相关专家
- `_call_experts_parallel()`：并行调用专家
- `_save_response()`：保存诊断响应

**工作流程**：
1. 收集全局上下文（日志、监控指标、集群状态）
2. 调用分类Agent识别故障类型
3. 根据故障类型选择相关专家
4. 并行调用选定的专家Agent
5. 调用讨论Agent综合专家意见
6. 构建并返回诊断报告

### 3.2 LLM客户端 (LLMClient)

**文件位置**：`llm_client.py`

**功能**：
- 统一封装LLM调用接口
- 支持多种模型（Qwen-8B、GPT-4o、DeepSeek-R1）
- 实现Role Token注入机制
- 处理JSON格式输出

**支持的模型**：
- **qwen-8b**：通过vLLM服务调用本地Qwen-8B模型
- **gpt-4o**：通过OpenAI兼容API调用GPT-4o
- **deepseek-r1**：通过DeepSeek API调用DeepSeek-R1

**主要方法**：
- `generate(prompt, system_prompt, temperature, role_token)`：生成文本
- `generate_with_role(role, prompt, system_prompt)`：带Role Token的生成
- `generate_json(prompt, system_prompt, role_token)`：生成JSON格式输出

**Role Token机制**：
- 在prompt前注入`<ROLE=role_name>`标记
- 帮助模型理解当前Agent的角色和任务
- 提高模型输出的准确性和一致性

### 3.3 Agent基类 (BaseAgent)

**文件位置**：`base.py`

**功能**：
- 定义所有Agent的统一接口
- 实现工具调用机制
- 支持多轮工具调用循环

**抽象方法**：
- `build_prompt(input_data)`：构建prompt（子类必须实现）
- `parse_output(response)`：解析输出（子类必须实现）

**工具调用机制**：
- Agent可以通过返回特定JSON格式请求调用工具
- 支持最多`max_tool_calls`轮工具调用
- 工具结果会自动注入到下一轮prompt中

### 3.4 分类Agent (FaultClassifierAgent)

**文件位置**：`agents/classifier.py`

**功能**：
- 分析日志和监控指标
- 识别故障类型
- 输出结构化分类结果

**输出格式**：
```json
{
  "fault_type": "datanode_down",
  "confidence": 0.95,
  "category": "hdfs",
  "related_faults": ["under_replicated_blocks"],
  "reasoning": "分类理由"
}
```

**特点**：
- 基于故障类型库进行分类
- 输出置信度评估
- 识别可能相关的故障类型

### 3.5 专家Agent集合

**文件位置**：`agents/experts/`

**专家类型**：
1. **HDFSExpertAgent**：处理HDFS相关故障
   - DataNode下线
   - 集群ID不匹配
   - NameNode安全模式

2. **YARNExpertAgent**：处理YARN相关故障
   - ResourceManager故障
   - NodeManager故障
   - 资源分配问题

3. **MapReduceExpertAgent**：处理MapReduce相关故障
   - 任务失败
   - 内存不足
   - 磁盘空间不足

4. **NetworkExpertAgent**：处理网络相关故障
   - 网络连接问题
   - 端口占用
   - 网络延迟

5. **GenericExpertAgent**：处理通用故障
   - 未知故障类型
   - 跨组件故障

**共同特点**：
- 接收全局上下文（日志、指标、集群状态）
- 可以进行深度分析
- 可以调用工具获取更多信息
- 输出诊断文本和结构化结果

### 3.6 讨论Agent (DiscussionAgent)

**文件位置**：`agents/discussion.py`

**功能**：
- 综合多个专家的诊断结果
- 识别专家意见的一致性/冲突
- 识别联动故障
- 生成最终诊断报告

**输出格式**：
```json
{
  "consensus": true,
  "final_root_cause": "综合根因",
  "final_evidence": ["证据1", "证据2"],
  "final_fix_steps": ["步骤1", "步骤2"],
  "confidence": 0.95,
  "conflicts": null,
  "compound_faults": ["联动故障1"],
  "expert_agreement": {"hdfs_expert": 0.95}
}
```

### 3.7 上下文收集器 (ContextCollector)

**文件位置**：`utils/context_collector.py`

**功能**：
- 收集所有节点的日志
- 收集JMX监控指标
- 提取集群状态信息

**收集内容**：
- **日志**：所有节点的最新日志内容
- **监控指标**：NameNode、DataNode、ResourceManager等组件的JMX指标
- **集群状态**：DataNode数量、HDFS状态、存储信息等

### 3.8 专家选择器 (ExpertSelector)

**文件位置**：`utils/expert_selector.py`

**功能**：
- 根据故障类型选择主要专家
- 识别可能相关的专家
- 支持联动故障识别

**选择策略**：
- 根据故障类型库中的`category`字段确定主要专家
- 根据故障类型的特点添加相关专家
- 例如：DataNode下线故障会同时选择HDFS专家和网络专家

### 3.9 工具适配器 (ToolAdapter)

**文件位置**：`utils/tool_adapter.py`

**功能**：
- 将LangChain工具转换为普通函数
- 创建工具注册表
- 供Agent调用

**可用工具**：
- `get_cluster_logs`：获取集群所有节点日志
- `get_node_log`：获取指定节点日志
- `get_monitoring_metrics`：获取监控指标
- `search_logs_by_keyword`：搜索日志关键词
- `get_error_logs_summary`：获取错误日志摘要
- `hadoop_auto_operation`：执行Hadoop操作
- `execute_hadoop_command`：执行Hadoop命令
- `generate_repair_plan`：生成修复计划

### 3.10 响应格式化器 (ResponseFormatter)

**文件位置**：`utils/response_formatter.py`

**功能**：
- 将结构化诊断报告转换为对话式文本
- 清理LLM响应中的推理标记
- 格式化输出供用户阅读

**输出格式**：
- Markdown格式的对话式文本
- 包含分类结果、专家诊断、综合结论等部分
- 用户友好的展示格式

---

## 工作流程

### 4.1 完整诊断流程

```
用户输入
    │
    ▼
┌─────────────────────────────────────┐
│  步骤1：收集全局上下文                │
│  - 收集所有节点日志                   │
│  - 收集JMX监控指标                    │
│  - 提取集群状态信息                    │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│  步骤2：故障分类                      │
│  - 分类Agent分析日志和指标            │
│  - 识别故障类型                        │
│  - 输出分类结果和置信度                │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│  步骤3：选择相关专家                  │
│  - 根据故障类型选择主要专家            │
│  - 识别可能相关的专家                  │
│  - 生成专家列表                        │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│  步骤4：并行调用专家                  │
│  - 并行调用选定的专家Agent             │
│  - 每个专家独立分析                    │
│  - 可以调用工具获取更多信息            │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│  步骤5：综合讨论                      │
│  - 讨论Agent分析所有专家结果           │
│  - 识别一致性和冲突                    │
│  - 生成综合诊断报告                    │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│  步骤6：构建诊断报告                  │
│  - 整合分类、专家、讨论结果            │
│  - 格式化输出                          │
│  - 保存响应到文件                      │
└──────────────┬──────────────────────┘
               │
               ▼
           返回结果
```

### 4.2 专家Agent工作流程

```
接收输入（故障类型+全局上下文）
    │
    ▼
┌─────────────────────────────────────┐
│  构建诊断Prompt                      │
│  - 包含故障类型信息                   │
│  - 包含相关日志和指标                 │
│  - 包含用户查询（如果有）             │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│  调用LLM（带Role Token）             │
│  - 注入Role Token（如<ROLE=hdfs_expert>）│
│  - 使用系统提示                       │
│  - 生成诊断结果                        │
└──────────────┬──────────────────────┘
               │
               ▼
        是否需要工具？
    ┌──────────┴──────────┐
    │                      │
   是                      否
    │                      │
    ▼                      ▼
调用工具              解析输出
    │                      │
    └──────────┬──────────┘
               │
               ▼
        返回诊断结果
```

---

## 主要功能

### 5.1 故障诊断功能

#### 5.1.1 自动故障分类
- 基于日志和监控指标自动识别故障类型
- 支持多种故障类型（HDFS、YARN、MapReduce、网络等）
- 输出置信度评估

#### 5.1.2 多专家并行诊断
- 根据故障类型自动选择相关专家
- 多个专家并行分析，提高效率
- 每个专家独立输出诊断结果

#### 5.1.3 综合诊断报告
- 综合多个专家的意见
- 识别专家意见的一致性/冲突
- 识别联动故障
- 生成最终诊断报告和修复建议

### 5.2 监控功能

#### 5.2.1 实时监控
- 显示集群关键指标（DataNode数量、HDFS状态等）
- 支持手动刷新监控数据
- 可视化展示集群状态

#### 5.2.2 日志收集
- 自动收集所有节点的日志
- 支持增量日志读取
- 保存日志读取状态

### 5.3 工具集成功能

#### 5.3.1 日志查询工具
- 获取集群所有节点日志
- 获取指定节点日志
- 搜索日志关键词
- 获取错误日志摘要

#### 5.3.2 监控工具
- 获取实时监控指标（JMX）
- 查询集群状态

#### 5.3.3 操作工具
- 执行Hadoop命令
- 执行Hadoop集群操作（启动/停止/重启服务）
- 生成修复计划

### 5.4 Web界面功能

#### 5.4.1 交互式对话
- 支持自然语言查询
- 实时显示诊断进度
- 展示诊断结果

#### 5.4.2 模型切换
- 支持切换不同的大模型
- 实时切换，无需重启
- 自动清空对话历史

#### 5.4.3 文档导出
- 支持导出Word格式
- 支持导出PDF格式
- 自动下载生成的文档

### 5.5 多模型支持

#### 5.5.1 Qwen-8B（vLLM）
- 本地部署的Qwen-8B模型
- 通过vLLM服务调用
- 适合本地环境使用

#### 5.5.2 GPT-4o（OpenAI）
- 通过OpenAI兼容API调用
- 需要配置API密钥
- 适合云端部署

#### 5.5.3 DeepSeek-R1（DeepSeek）
- 通过DeepSeek API调用
- 需要配置API密钥
- 支持推理能力

---

## 技术特点

### 6.1 架构特点

#### 6.1.1 模块化设计
- 清晰的模块划分
- 低耦合、高内聚
- 易于扩展和维护

#### 6.1.2 统一接口
- 所有Agent继承BaseAgent基类
- 统一的输入输出格式
- 便于添加新的Agent

#### 6.1.3 工具注入机制
- 工具由外部注入，不在Agent内部硬编码
- 支持动态工具选择
- 提高灵活性

### 6.2 Role Token机制

#### 6.2.1 原理
- 在prompt前注入`<ROLE=role_name>`标记
- 帮助模型理解当前Agent的角色
- 提高输出的准确性和一致性

#### 6.2.2 优势
- 无需为每个Agent训练专门模型
- 通过prompt工程实现角色区分
- 降低实现复杂度

### 6.3 并行处理

#### 6.3.1 专家并行调用
- 使用ThreadPoolExecutor实现并行
- 多个专家同时分析，提高效率
- 自动处理异常情况

#### 6.3.2 异步处理
- Gradio界面支持异步响应
- 实时显示处理进度
- 提升用户体验

### 6.4 错误处理

#### 6.4.1 容错机制
- 各步骤都有异常处理
- 单个Agent失败不影响整体流程
- 返回友好的错误信息

#### 6.4.2 日志记录
- 详细的日志输出
- 便于问题排查
- 支持调试模式

---

## 使用说明

### 7.1 启动Web界面

#### 7.1.1 基本启动
```bash
cd /media/hnu/hnu2025/xiongkui/rca_docker/rca-main
python mutli_agent/gradio_demo.py
```

#### 7.1.2 访问界面
- 启动后会在终端显示访问URL（通常是 `http://127.0.0.1:7860`）
- 在浏览器中打开该URL即可使用

### 7.2 使用诊断功能

#### 7.2.1 输入查询
- 在输入框中输入自然语言查询
- 例如："查看集群状态，分析是否有故障"
- 点击"发送"按钮或按Enter键

#### 7.2.2 查看结果
- 诊断结果会实时显示在对话界面
- 包含分类结果、专家诊断、综合结论等
- 支持复制诊断结果

#### 7.2.3 切换模型
- 在模型选择下拉框中选择不同模型
- 切换后会自动清空对话历史
- 新对话将使用选定的模型

### 7.3 导出文档

#### 7.3.1 导出Word
- 点击"📄 导出Word"按钮
- 系统会自动生成Word文档
- 点击下载链接下载文档

#### 7.3.2 导出PDF
- 点击"📄 导出PDF"按钮
- 系统会自动生成PDF文档
- 点击下载链接下载文档

### 7.4 查看监控数据

#### 7.4.1 自动刷新
- 页面加载时自动刷新一次
- 显示最新的集群监控数据

#### 7.4.2 手动刷新
- 点击"🔄 手动刷新"按钮
- 立即更新监控数据

### 7.5 编程接口使用

#### 7.5.1 基本使用
```python
from mutli_agent import FaultOrchestrator, LLMClient

# 初始化LLM客户端
llm_client = LLMClient(model_name="qwen-8b")

# 初始化协调器
orchestrator = FaultOrchestrator(llm_client, model_name="qwen-8b")

# 执行诊断
result = orchestrator.diagnose("查看集群状态，分析是否有故障")
print(result)
```

#### 7.5.2 获取结构化结果
```python
# 获取结构化诊断报告
report = orchestrator.diagnose("用户查询", output_format="structured")
print(report["classification"])
print(report["expert_diagnoses"])
print(report["discussion"])
```

---

## 配置说明

### 8.1 模型配置

#### 8.1.1 vLLM配置（Qwen-8B）
- **服务地址**：`http://10.157.197.76:8001/v1`
- **模型路径**：`/media/hnu/LLM/hnu/LLM/Qwen3-8B`
- 配置位置：`cl_agent/config.py`中的`VLLM_BASE_URL`和`VLLM_MODEL_PATH`

#### 8.1.2 OpenAI配置（GPT-4o）
- **API地址**：通过环境变量`THIRD_PARTY_API_BASE_URL`配置
- **API密钥**：通过环境变量`THIRD_PARTY_API_KEY`配置
- 需要设置`.env`文件或环境变量

#### 8.1.3 DeepSeek配置（DeepSeek-R1）
- **API地址**：通过环境变量`THIRD_PARTY_API_BASE_URL`配置
- **API密钥**：通过环境变量`THIRD_PARTY_API_KEY`配置
- 需要设置`.env`文件或环境变量

### 8.2 集群配置

#### 8.2.1 日志配置
- 日志文件配置：`cl_agent/config.py`中的`LOG_FILES_CONFIG`
- 支持配置多个节点的日志路径
- 支持增量读取

#### 8.2.2 监控配置
- JMX接口配置：`cl_agent/config.py`中的监控相关配置
- 支持NameNode、DataNode、ResourceManager等组件的监控

### 8.3 故障类型库配置

#### 8.3.1 故障类型定义
- 配置位置：`cl_agent/config.py`中的`FAULT_TYPE_LIBRARY`
- 每个故障类型包含：
  - `fault_type`：故障名称
  - `category`：故障类别（hdfs/yarn/mapreduce/network/generic）
  - `severity`：严重程度
  - `description`：故障描述

#### 8.3.2 添加新故障类型
- 在`FAULT_TYPE_LIBRARY`中添加新条目
- 系统会自动识别并支持新故障类型

---

## 扩展指南

### 9.1 添加新专家Agent

#### 9.1.1 创建专家类
```python
from mutli_agent.base import BaseAgent

class NewExpertAgent(BaseAgent):
    def __init__(self, llm_client, tools=None):
        system_prompt = self._load_system_prompt()
        super().__init__(
            llm_client=llm_client,
            system_prompt=system_prompt,
            role="new_expert",
            tools=tools
        )
    
    def _load_system_prompt(self):
        return "你的系统提示..."
    
    def build_prompt(self, input_data):
        # 构建prompt逻辑
        return prompt
    
    def parse_output(self, response):
        # 解析输出逻辑
        return parsed_result
```

#### 9.1.2 注册专家
- 在`orchestrator.py`的`_init_experts()`方法中添加新专家
- 在`expert_selector.py`中添加故障类型到专家的映射

### 9.2 添加新工具

#### 9.2.1 创建工具函数
```python
def new_tool(param1, param2):
    """工具描述"""
    # 工具实现
    return result
```

#### 9.2.2 注册工具
- 在`tool_adapter.py`的`create_tools_registry()`方法中添加工具映射
- 在`get_tool_description()`方法中添加工具描述

### 9.3 添加新模型支持

#### 9.3.1 配置模型
- 在`llm_client.py`的`__init__()`方法中添加模型配置
- 配置`base_url`、`api_key`、`model`等参数

#### 9.3.2 更新界面
- 在`gradio_demo.py`的`MODEL_NAME_MAP`中添加新模型映射
- 更新模型选择下拉框

### 9.4 自定义输出格式

#### 9.4.1 修改响应格式化器
- 在`response_formatter.py`中修改`format_diagnosis_report()`方法
- 自定义输出格式和样式

#### 9.4.2 添加新输出格式
- 在`orchestrator.py`的`diagnose()`方法中添加新格式支持
- 创建对应的格式化函数

---

## 常见问题

### Q1: 如何切换模型？
**A**: 在Web界面的模型选择下拉框中选择不同模型，系统会自动切换并清空对话历史。

### Q2: 诊断结果保存在哪里？
**A**: 诊断结果保存在项目根目录的`return`文件夹中，文件名格式为`multi_agent_response_YYYYMMDD_HHMMSS.txt`。

### Q3: 如何添加新的故障类型？
**A**: 在`cl_agent/config.py`的`FAULT_TYPE_LIBRARY`中添加新条目，系统会自动识别。

### Q4: 专家Agent如何调用工具？
**A**: 专家Agent在输出中返回特定JSON格式（`{"action": "call_tool", "tool": "tool_name", "args": {...}}`），系统会自动调用工具并将结果注入到下一轮prompt中。

### Q5: 如何提高诊断准确性？
**A**: 
- 确保日志和监控数据完整
- 使用更强大的模型（如GPT-4o）
- 优化系统提示词
- 增加更多专家Agent

---

## 版本历史

### v1.0.0 (当前版本)
- 实现多智能体框架核心功能
- 支持分类→专家→讨论三阶段流程
- 支持多模型切换
- 实现Web界面
- 支持文档导出

---

## 联系与支持

如有问题或建议，请联系开发团队或提交Issue。

---

**文档版本**：v1.0.0  
**最后更新**：2025年1月  
**维护者**：开发团队
