# 文档导入功能实现说明

## 一、问题分析

### 原有问题
`knowledge_base.py` 中的 `init_sample_knowledge()` 函数只包含少量写死的示例数据：
- NameNodeExpert: 3条固定文本
- DataNodeExpert: 3条固定文本
- 其他知识库为空

这种方式无法满足实际需求，需要支持导入完整的文档。

### 解决方案
实现了完整的文档导入功能，支持：
1. 多种文档格式（TXT、Markdown、PDF等）
2. 自动文本分割（将长文档分割成适合检索的块）
3. 批量导入（支持单个文件和整个目录）
4. 元数据管理（为文档添加来源、分类等信息）

---

## 二、实现的功能

### 2.1 新增函数

#### 1. `load_document(file_path, encoding="utf-8")`
- **功能**: 加载文档文件，自动识别格式
- **支持格式**: `.txt`, `.md`, `.markdown`, `.pdf`
- **返回**: `List[Document]`

#### 2. `split_documents(documents, chunk_size=500, chunk_overlap=50, separators=None)`
- **功能**: 将文档分割成较小的块
- **参数**:
  - `chunk_size`: 每个块的最大字符数（推荐500-1000）
  - `chunk_overlap`: 相邻块重叠字符数（推荐50-200）
  - `separators`: 分割符列表（中文友好）
- **返回**: 分割后的 `List[Document]`

#### 3. `import_document_to_kb(file_path, kb_name, ...)`
- **功能**: 将单个文档导入到指定知识库
- **参数**: 文件路径、知识库名称、分块参数、元数据等
- **返回**: 导入结果字典（包含成功状态、块数等信息）

#### 4. `import_directory_to_kb(directory_path, kb_name, ...)`
- **功能**: 批量导入目录中的所有文档
- **参数**: 目录路径、知识库名称、文件扩展名过滤等
- **返回**: 批量导入结果（包含成功/失败文件列表）

---

## 三、Hadoop和Docker文档资源

### 3.1 Hadoop文档资源（已验证有效）

#### 方式一：官方中文文档（在线+PDF）
1. **Apache Hadoop 官方中文文档**
   - 在线地址: https://hadoop.apache.org/docs/r1.0.4/cn/
   - 包含内容: HDFS用户指南、MapReduce教程、集群管理、故障排查等
   - 下载方式: 部分页面提供PDF下载链接，或使用浏览器打印功能保存为PDF

2. **Hadoop 中文网文档**
   - 在线地址: https://hadoop.org.cn/docs
   - 包含内容: Hadoop各组件详细中文文档（Common、HDFS、MapReduce、YARN等）
   - 特点: 内容丰富，持续更新，支持在线阅读

#### 方式二：GitHub源码（Markdown格式，推荐）
3. **Apache Hadoop GitHub仓库**
   ```bash
   # 克隆Hadoop源码仓库
   git clone https://github.com/apache/hadoop.git
   cd hadoop
   
   # Markdown文档位置（多个位置）
   # HDFS文档
   cd hadoop-hdfs-project/hadoop-hdfs/src/site/markdown/
   
   # YARN文档
   cd hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/src/site/markdown/
   
   # Common文档
   cd hadoop-project-dist/hadoop-common/src/site/markdown/
   ```
   - 格式: 原生Markdown文件，可直接导入
   - 优势: 文档完整，格式规范，易于批量处理

#### 方式三：PDF书籍资源
4. **《Hadoop 权威指南》第三版中文版 PDF**
   - 下载地址: https://www.iteblog.com/pdf/1919.pdf
   - 内容: 全面介绍Hadoop的权威书籍，涵盖基础到高级内容
   - 格式: PDF，可使用工具转换为Markdown

5. **《Hadoop 权威指南》第四版英文版 PDF**
   - 下载地址: https://www.iteblog.com/pdf/1373.pdf
   - 内容: 最新版本，内容更全面
   - 格式: PDF（英文版）

#### 方式四：其他中文教程资源
6. **公有云文档中心 - Hadoop使用指南**
   - 在线地址: https://docsv4embed.qingcloud.com/user_guide/bigdata/qingmr/developer_manual/hadoop/
   - 内容: Hadoop安装、配置和使用示例
   - 特点: 适合实际操作参考

#### 推荐的文档内容
- **HDFS用户指南**: HDFS架构、操作命令、配置参数
- **YARN文档**: YARN架构、资源管理、应用调度
- **MapReduce文档**: MapReduce编程模型、API使用
- **集群管理文档**: 集群部署、配置调优、监控运维
- **故障排查指南**: 常见问题诊断、日志分析、性能优化

### 3.2 Hadoop故障诊断专用文档资源（重点推荐）⭐

> **说明**: 以下文档专门针对Hadoop集群故障诊断和问题解决，非常适合构建故障诊断知识库。

#### 故障诊断书籍（PDF格式）
1. **《Hadoop权威指南》第三版/第四版 - 故障排除章节**
   - 下载地址: https://www.iteblog.com/pdf/1919.pdf (第三版中文)
   - 下载地址: https://www.iteblog.com/pdf/1373.pdf (第四版英文)
   - 重点章节: 故障排除、性能调优、集群运维
   - 适用场景: 系统学习故障诊断方法
   - 格式: PDF，需转换为Markdown

2. **《Hadoop海量数据处理：技术原理与项目实践》**
   - 下载地址: https://www.tup.tsinghua.edu.cn/upload/books/yz/106749-01.pdf
   - 内容: 包含集群故障处理的实际案例
   - 特点: 理论与实践结合，包含故障处理章节
   - 格式: PDF

#### 故障诊断实践指南（在线文档，可转换为Markdown）
3. **《Hadoop集群故障修复指南》- 百度云**
   - 在线地址: https://cloud.baidu.com/article/2749881
   - 内容: 
     - 数据损坏修复方法
     - 任务失败处理
     - 配置错误排查
     - 实用的诊断命令和步骤
   - 特点: 实战性强，包含具体命令示例
   - 获取方式: 在线阅读，使用浏览器插件保存为Markdown

4. **《远程调试Hadoop集群故障的方法与实践指南》- 袋鼠云**
   - 在线地址: https://www.dtstack.com/bbs/article/49665
   - 内容:
     - 远程环境下的故障调试方法
     - 常见故障类型分析
     - 故障排查步骤和工具
     - 实践案例分享
   - 特点: 针对远程调试场景，实用性强
   - 获取方式: 在线阅读，可转换为Markdown

5. **《诊断并解决Hadoop集群常见问题》- 袋鼠云**
   - 在线地址: https://www.dtstack.com/bbs/article/17209
   - 内容: Hadoop集群常见问题及诊断解决方法
   - 特点: 问题导向，快速定位问题根源
   - 获取方式: 在线阅读

#### 云服务商故障排除文档（PDF格式）
6. **《MapReduce服务故障排除》- 华为云**
   - 下载地址: https://support.huaweicloud.com/trouble-mrs/mrs-trouble-hec-pdf.pdf
   - 内容:
     - MapReduce服务常见故障
     - 故障诊断步骤
     - 解决方案和最佳实践
   - 特点: 官方文档，内容系统全面
   - 格式: PDF，可直接下载

7. **《MapReduce服务用户指南》- 华为云**
   - 下载地址: https://support.huaweicloud.com/intl/zh-cn/eu-west-0-usermanual-mrs/eu-west-0-usermanual-mrs-cn.pdf
   - 内容: 包含故障排除章节
   - 格式: PDF

#### 故障处理机制文档
8. **《Hadoop MapReduce故障处理与恢复机制》**
   - 下载地址: https://edu.51cto.com/file/94211.html
   - 内容:
     - 任务失败处理机制
     - 任务挂起问题
     - Application Master失败
     - Node Manager失败
     - Resource Manager失败
     - 各种故障的成因、影响及恢复策略
   - 特点: 深入分析故障处理机制
   - 格式: 需要注册下载

#### 高可用和故障转移文档
9. **《Hadoop3.x高可用安装手册》- 墨天轮**
   - 在线地址: https://www.modb.pro/db/189226
   - 内容:
     - Hadoop 3.x高可用配置
     - 故障转移机制
     - 故障排除方法
   - 特点: 针对Hadoop 3.x版本，包含故障排除内容
   - 获取方式: 在线阅读，可保存为PDF或转换为Markdown

#### 故障诊断知识库构建建议
**推荐导入顺序**:
1. **优先导入**: 《MapReduce服务故障排除》(华为云PDF) - 内容系统，可直接下载
2. **其次导入**: 《Hadoop集群故障修复指南》(百度云) - 实战性强
3. **补充导入**: 《远程调试Hadoop集群故障指南》(袋鼠云) - 远程场景
4. **系统学习**: 《Hadoop权威指南》故障排除章节 - 理论基础

**知识库分类建议**:
- **HistoryCases**: 导入故障案例类文档（百度云、袋鼠云的文章）
- **NameNodeExpert**: 导入NameNode相关故障文档
- **DataNodeExpert**: 导入DataNode相关故障文档
- **YARNExpert**: 导入YARN/MapReduce故障处理文档（华为云文档）

### 3.3 Docker文档资源

#### 官方文档
1. **Docker官网**
   - 英文: https://docs.docker.com/
   - 中文: https://docs.docker.com/zh-cn/

2. **GitHub源码（推荐）**
   ```bash
   git clone https://github.com/docker/docs.git
   cd docs/content/
   ```
   - 文档位置: `content/` 目录
   - 格式: Markdown文件，可直接导入

3. **推荐的文档内容**
   - Docker基础教程
   - Docker Compose指南
   - Docker网络配置
   - Docker存储管理
   - Docker故障排查

---

## 四、使用示例

### 4.1 快速开始

```python
from lc_agent.knowledge_base import import_document_to_kb

# 导入单个文档
result = import_document_to_kb(
    file_path="/path/to/hadoop-hdfs-guide.md",
    kb_name="HadoopDocs",
    chunk_size=500,
    chunk_overlap=50
)

print(result)
# {'success': True, 'kb_name': 'HadoopDocs', 'file_name': 'hadoop-hdfs-guide.md', 
#  'total_chunks': 45, 'message': '成功导入 45 个文档块'}
```

### 4.2 批量导入

```python
from lc_agent.knowledge_base import import_directory_to_kb

# 导入整个目录
result = import_directory_to_kb(
    directory_path="/path/to/hadoop-docs",
    kb_name="HadoopDocs",
    chunk_size=500,
    chunk_overlap=50,
    file_extensions=['.md', '.txt', '.pdf']
)

print(f"成功导入: {result['success_files']}/{result['total_files']} 个文件")
```

### 4.3 完整工作流程

#### 方式A：从GitHub克隆Markdown文档（推荐）
```bash
# 1. 克隆Hadoop源码仓库
git clone https://github.com/apache/hadoop.git
cd hadoop

# 2. 选择要导入的文档目录（例如HDFS文档）
cd hadoop-hdfs-project/hadoop-hdfs/src/site/markdown/

# 3. 运行导入脚本
python import_docs_example.py
```

#### 方式B：下载PDF并转换为Markdown
```bash
# 1. 下载PDF文档（如《Hadoop权威指南》）
wget https://www.iteblog.com/pdf/1919.pdf -O hadoop-guide.pdf

# 2. 使用pandoc转换为Markdown（需要安装pandoc）
pandoc hadoop-guide.pdf -o hadoop-guide.md

# 3. 导入Markdown文档
python -c "
from lc_agent.knowledge_base import import_document_to_kb
result = import_document_to_kb('hadoop-guide.md', 'HadoopDocs')
print(result)
"
```

#### 方式C：从在线文档手动保存
1. 访问 https://hadoop.apache.org/docs/r1.0.4/cn/
2. 使用浏览器打印功能（Ctrl+P）保存为PDF
3. 使用pandoc或其他工具转换为Markdown
4. 导入到知识库

#### 方式D：导入故障诊断文档（推荐用于故障诊断功能）⭐
```bash
# 1. 下载华为云MapReduce故障排除PDF（可直接导入）
wget https://support.huaweicloud.com/trouble-mrs/mrs-trouble-hec-pdf.pdf -O mrs-troubleshooting.pdf

# 2. 直接导入PDF到YARNExpert知识库（支持PDF格式）
python -c "
from lc_agent.knowledge_base import import_document_to_kb

# 导入故障排除文档到YARNExpert知识库
result = import_document_to_kb(
    file_path='mrs-troubleshooting.pdf',
    kb_name='YARNExpert',
    chunk_size=500,
    chunk_overlap=50,
    metadata={'source': '华为云MapReduce故障排除', 'type': '故障诊断'}
)
print(result)
"

# 3. 批量导入多个故障诊断文档
python -c "
from lc_agent.knowledge_base import import_document_to_kb, import_directory_to_kb

# 导入故障案例到HistoryCases知识库
import_document_to_kb(
    'hadoop-cluster-troubleshooting.md',  # 从在线文章转换的Markdown
    kb_name='HistoryCases',
    metadata={'source': '百度云故障修复指南', 'type': '故障案例'}
)

# 批量导入故障诊断文档目录
import_directory_to_kb(
    directory_path='./troubleshooting_docs',
    kb_name='HistoryCases',
    file_extensions=['.md', '.pdf', '.txt'],
    metadata={'type': '故障诊断'}
)
```

**故障诊断文档导入完整示例**:
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
故障诊断文档导入脚本
将Hadoop故障诊断相关文档导入到知识库
"""

from lc_agent.knowledge_base import import_document_to_kb, import_directory_to_kb
import logging

logging.basicConfig(level=logging.INFO)

# 1. 导入华为云MapReduce故障排除文档（PDF）
print("导入MapReduce故障排除文档...")
result1 = import_document_to_kb(
    file_path="mrs-troubleshooting.pdf",
    kb_name="YARNExpert",
    chunk_size=500,
    chunk_overlap=50,
    metadata={
        "source": "华为云MapReduce故障排除",
        "type": "故障诊断",
        "category": "MapReduce"
    }
)
print(f"结果: {result1}")

# 2. 导入故障案例文档（Markdown）
print("\n导入故障案例文档...")
result2 = import_document_to_kb(
    file_path="hadoop-cluster-troubleshooting.md",
    kb_name="HistoryCases",
    chunk_size=600,
    chunk_overlap=60,
    metadata={
        "source": "百度云故障修复指南",
        "type": "故障案例",
        "category": "集群故障"
    }
)
print(f"结果: {result2}")

# 3. 批量导入故障诊断文档目录
print("\n批量导入故障诊断文档...")
result3 = import_directory_to_kb(
    directory_path="./troubleshooting_docs",
    kb_name="HistoryCases",
    chunk_size=500,
    chunk_overlap=50,
    file_extensions=['.md', '.pdf', '.txt'],
    metadata={"type": "故障诊断"}
)
print(f"批量导入结果: {result3}")

print("\n✅ 故障诊断文档导入完成！")
```

---

## 五、技术实现细节

### 5.1 文档加载器

使用 `langchain_community.document_loaders`:
- `TextLoader`: 文本文件
- `PyPDFLoader`: PDF文件
- `UnstructuredMarkdownLoader`: Markdown文件
- `UnstructuredFileLoader`: 通用文件加载器

### 5.2 文本分割

使用 `RecursiveCharacterTextSplitter`:
- 递归分割，优先使用大分割符
- 中文友好分割符: `["\n\n", "\n", "。", "！", "？", ". ", " ", ""]`
- 可配置块大小和重叠大小

### 5.3 向量化存储

- 使用现有的 `SimpleEmbeddings` 进行向量化
- 使用 `FAISS` 存储向量索引
- 自动保存到磁盘

---

## 六、参数调优建议

### 6.1 chunk_size（文本块大小）

| 文档类型 | 推荐值 | 说明 |
|---------|--------|------|
| 中文文档 | 500-800 | 考虑中文字符占用 |
| 英文文档 | 800-1000 | 英文单词较长 |
| 代码文档 | 300-500 | 代码块较小 |
| 技术文档 | 500-700 | 平衡上下文和精度 |

### 6.2 chunk_overlap（重叠大小）

- **推荐值**: chunk_size 的 10-20%
- **作用**: 保持上下文连续性，避免重要信息被分割
- **示例**: chunk_size=500 时，chunk_overlap=50-100

### 6.3 知识库选择

根据文档内容选择合适的知识库：

| 知识库 | 用途 | 示例文档 | 故障诊断推荐 |
|--------|------|----------|------------|
| HadoopDocs | Hadoop官方文档 | HDFS指南、YARN文档 | 一般文档，非故障诊断专用 |
| NameNodeExpert | NameNode相关 | NameNode故障案例、NameNode故障排查 | ⭐ NameNode启动失败、内存溢出、配置错误等 |
| DataNodeExpert | DataNode相关 | DataNode故障案例、DataNode连接问题 | ⭐ DataNode无法连接、磁盘空间不足、心跳超时等 |
| YARNExpert | YARN/MapReduce相关 | YARN配置、调优、MapReduce故障处理 | ⭐ MapReduce任务失败、ResourceManager故障、任务挂起等 |
| HistoryCases | 历史案例 | 故障诊断记录、故障修复指南、故障案例 | ⭐⭐ **重点推荐**：所有故障诊断文档优先导入这里 |
| DockerDocs | Docker文档 | Docker官方文档（新建） | Docker相关故障 |

**故障诊断文档导入建议**:
- **HistoryCases**: 优先导入所有故障诊断文档（百度云、袋鼠云等故障案例文章）
- **YARNExpert**: 导入MapReduce/YARN相关故障排除文档（如华为云MapReduce故障排除PDF）
- **NameNodeExpert**: 导入NameNode特定故障文档
- **DataNodeExpert**: 导入DataNode特定故障文档

**推荐导入顺序**（针对故障诊断功能）:
1. **第一步**: 导入《MapReduce服务故障排除》(华为云PDF) → `YARNExpert`
2. **第二步**: 导入《Hadoop集群故障修复指南》等故障案例 → `HistoryCases`
3. **第三步**: 导入《远程调试Hadoop集群故障指南》 → `HistoryCases`
4. **第四步**: 根据实际需求，导入特定组件的故障文档到对应Expert知识库

---

## 七、依赖安装

### 必需依赖
```bash
pip install langchain-community
pip install langchain  # LangChain核心包
pip install langchain-text-splitters  # 文本分割器（LangChain 1.0.x需要单独安装）
```

**注意**: 在 LangChain 1.0.x 版本中，`RecursiveCharacterTextSplitter` 已移至独立的 `langchain-text-splitters` 包中，需要单独安装。

### 可选依赖（根据文档格式）
```bash
# PDF支持
pip install pypdf
# 或
pip install pdfminer.six

# Markdown增强支持
pip install unstructured
```

---

## 八、文件清单

### 修改的文件
- `lc_agent/knowledge_base.py`: 添加文档导入功能

### 新增的文件
- `文档导入指南.md`: 详细的使用指南和文档资源
- `文档导入功能说明.md`: 本文件，功能实现说明
- `import_docs_example.py`: 使用示例脚本

---

## 九、下一步建议

1. **准备文档**
   - 克隆Hadoop和Docker官方文档
   - 整理历史故障案例文档

2. **导入文档**
   - 使用 `import_docs_example.py` 作为参考
   - 根据实际需求调整参数

3. **测试检索**
   - 导入后测试知识库检索功能
   - 验证检索结果的准确性

4. **持续更新**
   - 定期更新文档内容
   - 添加新的故障案例

---

## 十、常见问题

### Q1: 导入失败，提示需要安装 langchain_community
**A**: 运行 `pip install langchain-community`

### Q2: PDF文件无法加载
**A**: 安装 `pip install pypdf` 或 `pip install pdfminer.six`

### Q3: 中文文档乱码
**A**: 确保文件是UTF-8编码，或在导入时指定编码: `encoding="utf-8"`

### Q4: 导入速度慢
**A**: 
- 减少 `chunk_size` 可以加快向量化速度
- 使用更快的嵌入模型
- 考虑批量导入时使用多线程（未来可优化）

### Q5: 如何将PDF转换为Markdown？
**A**: 推荐使用以下工具：
- **pandoc**（推荐）: `pandoc input.pdf -o output.md`
- **在线工具**: 使用 https://www.zamzar.com/convert/pdf-to-md/ 等在线转换服务
- **Python库**: 使用 `pdfplumber` 或 `PyPDF2` 提取文本后手动格式化

### Q6: GitHub上的文档路径找不到？
**A**: Hadoop仓库结构可能随版本变化，建议：
- 使用 `find` 命令查找: `find hadoop -name "*.md" -type f`
- 或直接搜索: `find hadoop -path "*/site/markdown/*.md"`

---

## 十一、文档下载工具推荐

### 11.1 命令行工具

#### wget/curl - 下载PDF文档
```bash
# 下载《Hadoop权威指南》PDF
wget https://www.iteblog.com/pdf/1919.pdf -O hadoop-guide.pdf

# 或使用curl
curl -L https://www.iteblog.com/pdf/1919.pdf -o hadoop-guide.pdf
```

#### git - 克隆GitHub文档
```bash
# 克隆Hadoop仓库（较大，约几百MB）
git clone https://github.com/apache/hadoop.git

# 只克隆最新版本（节省空间）
git clone --depth 1 https://github.com/apache/hadoop.git
```

#### pandoc - PDF转Markdown
```bash
# 安装pandoc
# Ubuntu/Debian: sudo apt-get install pandoc
# macOS: brew install pandoc
# 或从 https://pandoc.org/installing.html 下载

# 转换PDF为Markdown
pandoc input.pdf -o output.md

# 批量转换
for pdf in *.pdf; do
    pandoc "$pdf" -o "${pdf%.pdf}.md"
done
```

### 11.2 Python脚本示例

#### 批量下载GitHub Markdown文件
```python
import os
import subprocess
from pathlib import Path

# 克隆仓库
repo_url = "https://github.com/apache/hadoop.git"
local_dir = "hadoop_docs"
subprocess.run(["git", "clone", "--depth", "1", repo_url, local_dir])

# 查找所有Markdown文件
md_files = list(Path(local_dir).rglob("*.md"))
print(f"找到 {len(md_files)} 个Markdown文件")
```

#### PDF转Markdown（使用pdfplumber）
```python
import pdfplumber

def pdf_to_markdown(pdf_path, md_path):
    with pdfplumber.open(pdf_path) as pdf:
        text = ""
        for page in pdf.pages:
            text += page.extract_text() + "\n\n"
    
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(text)

# 使用
pdf_to_markdown("hadoop-guide.pdf", "hadoop-guide.md")
```

### 11.3 在线工具

- **PDF转Markdown**: https://www.zamzar.com/convert/pdf-to-md/
- **网页转Markdown**: 浏览器插件 "MarkDownload" 或 "Copy as Markdown"
- **在线Markdown编辑器**: https://dillinger.io/ (可导入导出)

---

**实现时间**: 2025-01-XX  
**版本**: knowledge_base.py (支持文档导入版本)  
**最后更新**: 2025-01-XX (更新文档资源链接)

