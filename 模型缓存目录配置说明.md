# 模型缓存目录配置说明

## 配置位置

模型缓存目录已设置为：**`D:\models`**

## 修改的文件

1. **`lc_agent/knowledge_base.py`**
   - 设置环境变量 `TRANSFORMERS_CACHE` 和 `HF_HOME`
   - 在加载模型时指定 `cache_folder` 参数

2. **`lc_agent/tool_matcher.py`**
   - 设置环境变量 `TRANSFORMERS_CACHE` 和 `HF_HOME`
   - 在加载模型时指定 `cache_folder` 参数

## 工作原理

### 方式1：环境变量（全局设置）

```python
import os
MODEL_CACHE_DIR = os.path.join("D:", "models")
os.environ['TRANSFORMERS_CACHE'] = MODEL_CACHE_DIR
os.environ['HF_HOME'] = MODEL_CACHE_DIR
```

### 方式2：cache_folder参数（局部设置）

```python
model = SentenceTransformer(
    'sentence-transformers/all-mpnet-base-v2',
    cache_folder=MODEL_CACHE_DIR
)
```

## 验证配置

运行以下代码验证模型是否下载到D:\models：

```python
from sentence_transformers import SentenceTransformer
import os

# 检查目录
cache_dir = "D:\\models"
print(f"缓存目录: {cache_dir}")
print(f"目录存在: {os.path.exists(cache_dir)}")

# 加载模型（会自动下载到D:\models）
model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', cache_folder=cache_dir)

# 检查模型文件
model_files = os.listdir(cache_dir) if os.path.exists(cache_dir) else []
print(f"模型文件: {model_files}")
```

## 注意事项

1. **首次运行**：会自动创建 `D:\models` 目录并下载模型
2. **下载大小**：约 80-90 MB（all-mpnet-base-v2模型）
3. **需要网络**：首次下载需要网络连接
4. **后续使用**：模型会从 `D:\models` 加载，无需重新下载

## 手动创建目录（可选）

如果希望提前创建目录：

```bash
mkdir D:\models
```

## 查看模型文件

下载后，可以在以下位置查看模型文件：

```
D:\models\
├── sentence-transformers_all-mpnet-base-v2/
│   ├── config.json
│   ├── pytorch_model.bin
│   ├── tokenizer.json
│   └── ...
```

---

**配置完成**：模型将自动下载并缓存到 `D:\models` 目录

