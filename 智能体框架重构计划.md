查看 `mutli_agent` 目录的当前状态，结合多专家会诊和 Discussion Agent，制定实施计划：


[3 tools called]


结合多专家会诊、Discussion Agent 和全局上下文注入，给出实施计划：

## 多智能体框架实施计划

### 一、目录结构设计

```
mutli_agent/
├── __init__.py                    # 包初始化，导出主要接口
│
├── base.py                        # BaseAgent抽象基类（极简设计）
├── llm_client.py                 # LLM调用封装（替代LangChain）
├── schemas.py                     # 输出格式Schema定义
│
├── orchestrator.py                # ⭐ 总协调器（核心，包含全局上下文管理）
│
├── agents/                        # 各个Agent实现
│   ├── __init__.py
│   ├── classifier.py             # 分类Agent（无工具）
│   ├── discussion.py              # ⭐ 讨论/总结Agent（新增）
│   │
│   └── experts/                   # 专家Agents
│       ├── __init__.py
│       ├── base_expert.py         # 专家Agent基类（可选）
│       ├── hdfs_expert.py         # HDFS专家
│       ├── yarn_expert.py        # YARN专家
│       ├── mapreduce_expert.py   # MapReduce专家
│       └── network_expert.py     # 网络专家（可选，处理网络相关故障）
│
└── utils/                         # 工具函数
    ├── __init__.py
    ├── context_collector.py       # ⭐ 全局上下文收集器
    ├── expert_selector.py         # ⭐ 专家选择器（根据故障类型选择相关专家）
    └── tool_adapter.py            # 工具适配器（将LangChain工具转换为普通函数）
```

### 二、核心模块设计

#### 2.1 `base.py` - BaseAgent抽象基类

职责：
- 定义Agent接口（`build_prompt`, `parse_output`, `run`）
- 提供LLM调用封装
- 支持工具注入（可选，由子类决定）
- 支持Role Token

设计要点：
- 极简设计（ChatGPT方案）
- 工具由外部注入，不在Agent内部硬编码
- `run()`方法确保prompt包含Role Token

#### 2.2 `llm_client.py` - LLM调用封装

职责：
- 封装vLLM/OpenAI API调用
- 支持role token注入
- 统一错误处理和重试
- 替代LangChain的ChatOpenAI

设计要点：
- 直接调用HTTP API，不依赖LangChain
- `generate()`和`generate_json()`两种模式
- `generate_with_role(role, prompt)`方法

#### 2.3 `orchestrator.py` - 总协调器（核心）

职责：
- 管理整个诊断流程
- 收集全局上下文（日志、指标、集群状态）
- 调用分类Agent
- 根据分类结果选择相关专家（不是单个专家）
- 并行调用多个专家Agent
- 注入全局上下文到每个专家
- 调用Discussion Agent进行总结
- 返回最终结果

关键方法：
```python
class FaultOrchestrator:
    def __init__(self, llm_client, tools_registry):
        # 初始化所有Agent和工具
    
    def _collect_global_context(self) -> Dict:
        """收集全局上下文（日志、指标、集群状态）"""
    
    def _select_relevant_experts(self, fault_type: str) -> List[str]:
        """根据故障类型选择相关专家（不是所有专家）"""
    
    def _identify_related_faults(self, primary_fault: str, context: Dict) -> List[str]:
        """识别可能相关的故障类型（用于联动错误检测）"""
    
    def diagnose(self, user_input: str) -> Dict:
        """完整诊断流程：
        1. 收集全局上下文
        2. 分类
        3. 选择相关专家
        4. 并行调用专家（注入全局上下文）
        5. Discussion Agent总结
        6. 返回结果
        """
```

#### 2.4 `agents/classifier.py` - 分类Agent

职责：
- 故障类型分类
- 输出结构化JSON（fault_type, confidence, category, related_faults）
- 不调用工具（纯分类任务）

设计要点：
- 继承BaseAgent
- Prompt包含`<ROLE=classifier>`token
- 输出强制JSON格式
- 可以输出`related_faults`字段（用于识别可能相关的故障）

#### 2.5 `agents/discussion.py` - Discussion Agent（新增）

职责：
- 综合多个专家的诊断结果
- 识别一致性/冲突
- 解决冲突（如果有）
- 识别联动关系（复合故障）
- 生成最终诊断报告

设计要点：
- 继承BaseAgent
- Prompt包含`<ROLE=discussion>`token
- 输入：多个专家的诊断结果 + 全局上下文
- 输出：综合诊断报告（JSON格式，包含consensus, conflicts, compound_faults等字段）

#### 2.6 `agents/experts/` - 专家Agents

职责：
- 深度故障诊断
- 调用工具获取额外信息（如需要）
- 输出详细诊断报告（对话式文本）

设计要点：
- 每个专家继承BaseAgent
- 工具由Orchestrator注入
- Prompt包含对应的role token（`<ROLE=hdfs_expert>`等）
- 接收全局上下文（解决联动错误问题）

#### 2.7 `utils/context_collector.py` - 全局上下文收集器

职责：
- 收集所有节点日志
- 收集JMX监控指标
- 收集集群状态信息
- 统一格式化为全局上下文字典

设计要点：
- 复用现有的`log_reader.py`和`monitor_collector.py`
- 提供统一的接口：`collect_all_context() -> Dict`

#### 2.8 `utils/expert_selector.py` - 专家选择器

职责：
- 根据故障类型选择相关专家
- 识别可能相关的故障类型
- 管理故障类型到专家的映射关系

设计要点：
- 基于`FAULT_TYPE_LIBRARY`配置
- 支持"主要专家"和"可能相关专家"的概念
- 例如：`datanode_down` → 主要：`hdfs_expert`，可能相关：`network_expert`

#### 2.9 `utils/tool_adapter.py` - 工具适配器

职责：
- 将LangChain的`@tool`装饰器函数转换为普通函数
- 适配现有工具系统，供新框架使用

设计要点：
- 提取LangChain工具的实际函数
- 处理参数转换
- 保持接口兼容

### 三、关键设计决策

#### 3.1 多专家会诊流程

```
用户输入
    ↓
Orchestrator收集全局上下文
    ↓
分类Agent（基于全局上下文）
    ↓
选择相关专家（不是所有专家）
    ↓
并行调用多个专家（注入全局上下文）
├── HDFS专家 → 诊断结果A
├── YARN专家 → 诊断结果B（如果相关）
└── 网络专家 → 诊断结果C（如果相关）
    ↓
Discussion Agent（综合各专家意见）
    ↓
最终诊断报告
```

#### 3.2 全局上下文注入策略

每个专家Agent接收的输入：
```python
{
    "fault_type": "datanode_down",
    "logs": global_context["logs"],           # 全局日志
    "metrics": global_context["metrics"],     # 全局指标
    "cluster_state": global_context["state"], # 集群状态
    "related_faults": ["network_issue"],      # 可能相关的故障
    "other_experts_findings": {...}           # 其他专家的发现（可选）
}
```

#### 3.3 专家选择策略

```python
# 故障类型 → 专家映射
FAULT_EXPERT_MAPPING = {
    "datanode_down": {
        "primary": ["hdfs_expert"],
        "related": ["network_expert"]  # 可能相关
    },
    "mapreduce_memory_insufficient": {
        "primary": ["mapreduce_expert"],
        "related": ["yarn_expert"]  # 资源问题可能相关
    },
    # ...
}
```

#### 3.4 Discussion Agent的输入输出

输入：
```python
{
    "fault_type": "datanode_down",
    "expert_results": [
        {
            "expert": "hdfs_expert",
            "root_cause": "...",
            "evidence": [...],
            "fix_steps": [...]
        },
        {
            "expert": "network_expert",
            "root_cause": "...",
            "evidence": [...],
            "fix_steps": [...]
        }
    ],
    "global_context": {...}
}
```

输出：
```python
{
    "consensus": True/False,           # 专家意见是否一致
    "final_root_cause": "...",         # 综合根因
    "final_evidence": [...],           # 综合证据
    "final_fix_steps": [...],          # 综合修复步骤
    "confidence": 0.0-1.0,             # 置信度
    "conflicts": [...],                # 冲突描述（如有）
    "compound_faults": [...],          # 联动故障分析（如有）
    "expert_agreement": {...}          # 专家一致性分析
}
```

### 四、实施步骤（分阶段）

#### 阶段1：基础设施（2-3天）

1. 创建目录结构
2. 实现`llm_client.py`（LLM调用封装）
3. 实现`base.py`（BaseAgent抽象）
4. 实现`schemas.py`（输出格式定义）
5. 实现`utils/tool_adapter.py`（工具适配器）

#### 阶段2：上下文和选择器（1-2天）

1. 实现`utils/context_collector.py`（全局上下文收集）
2. 实现`utils/expert_selector.py`（专家选择器）
3. 测试上下文收集和专家选择逻辑

#### 阶段3：分类和专家Agent（3-4天）

1. 实现`agents/classifier.py`（分类Agent）
2. 实现`agents/experts/hdfs_expert.py`（先做一个专家）
3. 创建对应的prompt模板
4. 测试分类和诊断功能（mock LLM响应）

#### 阶段4：Discussion Agent（2-3天）

1. 实现`agents/discussion.py`（讨论Agent）
2. 创建discussion prompt模板
3. 测试多专家结果的综合

#### 阶段5：Orchestrator集成（2-3天）

1. 实现`orchestrator.py`（总协调器）
2. 集成所有组件
3. 实现并行调用逻辑
4. 端到端测试

#### 阶段6：完善和优化（3-5天）

1. 实现其他专家Agent（YARN、MapReduce）
2. 错误处理和降级策略
3. 日志和调试支持
4. 性能优化（缓存、异步等）

### 五、与现有系统的集成

#### 5.1 工具系统集成

- 复用`cl_agent/tools/tools.py`中的工具函数
- 通过`tool_adapter.py`适配LangChain工具
- Orchestrator负责工具注册和注入

#### 5.2 配置复用

- 复用`cl_agent/config.py`中的配置
- `FAULT_TYPE_LIBRARY`用于专家选择
- `LOG_FILES_CONFIG`用于上下文收集

#### 5.3 Prompt复用

- 复用`cl_agent/cluster_context.py`中的集群上下文信息
- 在prompt模板中组织role-specific的prompt
- 分类Agent：集群上下文 + 分类任务说明
- 专家Agent：集群上下文 + 专家角色说明 + 全局上下文

### 六、关键技术决策

#### 6.1 并行调用实现

```python
# 使用concurrent.futures实现并行调用
from concurrent.futures import ThreadPoolExecutor

with ThreadPoolExecutor(max_workers=len(experts)) as executor:
    futures = {
        executor.submit(expert.run, input_data): expert_name
        for expert_name, expert in experts.items()
    }
    results = {futures[f]: f.result() for f in futures}
```

#### 6.2 Role Token处理

- Prompt模板中显式包含Role Token
- LLM Client的`generate_with_role()`方法确保Role Token存在
- 与数据集格式保持一致

#### 6.3 错误处理策略

- 每个Agent独立try-catch
- 专家调用失败时，使用其他专家的结果
- Discussion Agent处理部分专家失败的情况

### 七、测试策略

#### 7.1 单元测试

- 每个Agent独立测试（mock LLM响应）
- Orchestrator路由逻辑测试
- 工具调用测试

#### 7.2 集成测试

- 端到端流程测试（分类→多专家→讨论）
- 与现有工具系统集成测试
- 错误场景测试（部分专家失败）

#### 7.3 对比测试

- 与现有LangChain Agent对比（功能一致性）
- 单专家 vs 多专家会诊对比（准确性提升）

### 八、潜在风险和应对

| 风险 | 应对策略 |
|------|---------|
| **并行调用成本高** | 智能选择专家（不是所有专家都参与） |
| **Discussion Agent冲突解决困难** | 先实现简单投票，后续增强 |
| **全局上下文过大** | 上下文压缩/摘要，只传递关键信息 |
| **工具调用循环** | 阶段1不实现工具调用，先验证核心流程 |

### 九、成功标准

#### 9.1 功能标准

- ✅ 能够正确分类故障类型
- ✅ 能够选择相关专家（不是所有专家）
- ✅ 多个专家能够并行诊断
- ✅ Discussion Agent能够综合各专家意见
- ✅ 能够识别联动故障（复合故障）

#### 9.2 代码质量标准

- ✅ 代码结构清晰，易于扩展
- ✅ 每个模块职责单一
- ✅ 有完整的错误处理
- ✅ 有日志和调试支持

#### 9.3 研究标准

- ✅ 流程完全可控（每一步可追踪）
- ✅ 便于论文方法部分描述
- ✅ 支持role token微调策略
- ✅ 能够处理联动错误

---

## 总结

该计划结合了：
1. ChatGPT的极简Agent设计
2. 多专家会诊模式
3. Discussion Agent讨论总结
4. 全局上下文注入（解决联动错误）
5. Role Token支持

实施顺序：基础设施 → 上下文收集 → 分类和专家 → Discussion → Orchestrator → 完善优化。

每个阶段都有明确的交付物和测试标准。

需要我开始实施吗？建议从阶段1（基础设施）开始。