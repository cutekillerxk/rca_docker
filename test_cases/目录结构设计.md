# test_cases 目录结构设计方案

## 方案一：按故障类型 + 测试用例编号（推荐）

### 结构
```
test_cases/
├── hdfs/
│   ├── datanode_down/
│   │   ├── case1/
│   │   │   ├── cluster_logs.txt
│   │   │   ├── metadata.json
│   │   │   └── ground_truth.json
│   │   ├── case2/
│   │   │   └── ...
│   │   └── README.md
│   ├── namenode_safemode/
│   │   └── ...
│   └── cluster_id_mismatch/
│       └── ...
├── yarn/
│   └── ...
└── mapreduce/
    └── ...
```

**优点**：
- 结构清晰，易于管理
- 每个故障类型可以有多个测试用例
- 便于扩展和维护

**缺点**：
- 目录层级较深（4层）

---

## 方案二：扁平化结构（简单）

### 结构
```
test_cases/
├── hdfs/
│   ├── datanode_down_case1.txt
│   ├── datanode_down_case1_metadata.json
│   ├── datanode_down_case1_ground_truth.json
│   ├── datanode_down_case2.txt
│   ├── namenode_safemode_case1.txt
│   └── ...
├── yarn/
│   └── ...
└── mapreduce/
    └── ...
```

**优点**：
- 结构简单，文件少
- 易于查找

**缺点**：
- 文件命名较长
- 同一故障类型的多个用例管理不便

---

## 方案三：混合结构（平衡）

### 结构
```
test_cases/
├── hdfs/
│   ├── datanode_down/
│   │   ├── case1_cluster_logs.txt
│   │   ├── case1_metadata.json
│   │   ├── case1_ground_truth.json
│   │   ├── case2_cluster_logs.txt
│   │   └── case2_metadata.json
│   └── ...
├── yarn/
│   └── ...
└── mapreduce/
    └── ...
```

**优点**：
- 目录层级适中（3层）
- 文件命名清晰
- 便于管理

**缺点**：
- 文件较多时可能显得杂乱

---

## 推荐方案：方案一

### 理由
1. **可扩展性强**：每个故障类型可以有多个测试用例
2. **组织清晰**：按故障类型分类，便于查找
3. **便于维护**：每个测试用例独立目录，便于管理
4. **符合现有结构**：与您现有的目录结构一致

### 完整示例

```
test_cases/
├── hdfs/
│   ├── datanode_down/
│   │   ├── case1/
│   │   │   ├── cluster_logs.txt          # 集群日志
│   │   │   ├── metadata.json             # 元数据
│   │   │   └── ground_truth.json         # 标准答案
│   │   ├── case2/
│   │   │   └── ...
│   │   └── README.md                     # 该故障类型说明
│   ├── namenode_safemode/
│   │   ├── case1/
│   │   │   └── ...
│   │   └── README.md
│   └── cluster_id_mismatch/
│       ├── case1/
│       │   └── ...
│       └── README.md
├── yarn/
│   ├── resourcemanager_down/
│   │   ├── case1/
│   │   │   └── ...
│   │   └── README.md
│   ├── nodemanager_down/
│   │   └── ...
│   └── yarn_config_error/
│       └── ...
└── mapreduce/
    ├── mapreduce_memory_insufficient/
    │   ├── case1/
    │   │   └── ...
    │   └── README.md
    ├── mapreduce_disk_insufficient/
    │   └── ...
    ├── mapreduce_shuffle_failed/
    │   └── ...
    └── mapreduce_task_timeout/
        └── ...
```

### 文件内容示例

#### metadata.json
```json
{
  "fault_type": "datanode_down",
  "fault_name": "DataNode下线",
  "category": "hdfs",
  "severity": "high",
  "description": "DataNode1 服务停止，NameNode检测到节点下线",
  "created_at": "2026-01-22T21:45:30",
  "source": "实际故障场景",
  "affected_nodes": ["datanode1"],
  "expected_symptoms": [
    "hdfs dfsadmin -report 显示 Dead datanodes > 0",
    "NameNode日志出现 'dead' 或 'removed' 关键字"
  ],
  "test_scenario": "手动停止datanode1容器，收集日志"
}
```

#### ground_truth.json
```json
{
  "fault_type": "datanode_down",
  "fault_name": "DataNode下线",
  "category": "hdfs",
  "severity": "high",
  "confidence": 0.95,
  "affected_nodes": ["datanode1"],
  "symptoms": [
    "hdfs dfsadmin -report 显示 Dead datanodes: 1",
    "NameNode日志显示: 'DatanodeRegistration for datanode1 is removed'",
    "jps命令在datanode1容器中看不到DataNode进程"
  ],
  "root_cause": {
    "primary_cause": "DataNode服务崩溃",
    "secondary_causes": [
      "容器停止运行"
    ],
    "evidence": [
      "NameNode日志: 'DatanodeRegistration for datanode1 is removed'",
      "hdfs dfsadmin -report: Dead datanodes: 1",
      "docker ps: datanode1容器状态为Exited"
    ]
  },
  "recommended_actions": [
    "检查DataNode容器状态: docker ps -a | grep datanode1",
    "重启DataNode服务: docker exec datanode1 sh -c 'su - hadoop -c \"hdfs --daemon start datanode\"'",
    "验证修复: hdfs dfsadmin -report"
  ]
}
```

## 使用建议

1. **初始阶段**：每个故障类型至少创建 1-2 个测试用例
2. **逐步扩展**：根据实际故障场景，逐步增加测试用例
3. **定期更新**：根据系统改进，更新 ground_truth.json
4. **文档维护**：每个故障类型目录下的 README.md 记录该故障的详细信息
