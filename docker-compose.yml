services:
  namenode:
    image: cutekiller/myhadoop-namenode:v1
    container_name: namenode
    hostname: namenode
    entrypoint: /bin/bash
    command: -c "service ssh start && trap 'wait' CHLD; while true; do sleep 86400 & wait; done"
    ports:
      - "0.0.0.0:9870:9870"   # NameNode Web UI (显式绑定到所有接口)
      - "0.0.0.0:9000:9000"   # HDFS RPC
      - "0.0.0.0:8020:8020"   # HDFS RPC (alternative)
      - "0.0.0.0:50070:50070" # NameNode Web UI (Hadoop 2.x, if applicable)
      - "0.0.0.0:2225:22"     # SSH (mapped to 2222 to avoid conflict with host SSH)
      - "0.0.0.0:9866:9864"   # HDFS RPC (alternative)
    networks:
      - hadoop-network
    volumes:
      - hadoop_namenode:/usr/local/hadoop/hdfs/namenode
      - /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime:ro
    restart: unless-stopped
    environment:
      - CLUSTER_NAME=myhadoop
      - TZ=Asia/Shanghai

  datanode1:
    image: cutekiller/myhadoop-datanode1:v1
    container_name: datanode1
    hostname: datanode1
    entrypoint: /bin/bash
    command: -c "service ssh start && trap 'wait' CHLD; while true; do sleep 86400 & wait; done"
    ports:
      - "0.0.0.0:9864:9864"   # DataNode Web UI (显式绑定到所有接口)
      - "0.0.0.0:2223:22"     # SSH (mapped to 2223)
    networks:
      - hadoop-network
    volumes:
      - hadoop_datanode1:/usr/local/hadoop/hdfs/datanode
      - /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime:ro
    depends_on:
      - namenode
    restart: unless-stopped
    environment:
      - TZ=Asia/Shanghai

  datanode2:
    image: cutekiller/myhadoop-datanode2:v1
    container_name: datanode2
    hostname: datanode2
    entrypoint: /bin/bash
    command: -c "service ssh start && trap 'wait' CHLD; while true; do sleep 86400 & wait; done"
    ports:
      - "0.0.0.0:9865:9864"   # DataNode Web UI (mapped to 9865 to avoid conflict, 显式绑定)
      - "0.0.0.0:2224:22"     # SSH (mapped to 2224)
    networks:
      - hadoop-network
    volumes:
      - hadoop_datanode2:/usr/local/hadoop/hdfs/datanode
      - /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime:ro
    depends_on:
      - namenode
    restart: unless-stopped
    environment:
      - TZ=Asia/Shanghai

networks:
  hadoop-network:
    driver: bridge
    name: hadoop-network

volumes:
  hadoop_namenode:
    name: hadoop_namenode
  hadoop_datanode1:
    name: hadoop_datanode1
  hadoop_datanode2:
    name: hadoop_datanode2

