好的，我来详细介绍这两个改进方案的设计思路和具体做法。

---

## 一、配置文件设计方案

### 1.1 设计目标

配置文件的核心目标是 **让大模型"看到"你看到的一切**。具体来说：

| 你知道的信息 | 大模型需要知道的 |
|-------------|-----------------|
| 集群有3个容器 | 容器名、IP、端口映射 |
| Hadoop装在哪里 | HADOOP_HOME路径、配置文件位置 |
| 用什么用户运行 | 用户名、权限说明 |
| 命令怎么执行 | 完整的命令格式模板 |
| 日志在哪里 | 日志路径、日志格式 |
| 常见问题有哪些 | 故障模式、症状、解决思路 |

### 1.2 配置文件结构设计

建议创建一个 **分层结构** 的配置文件，包含以下几个层次：

```
cluster_context.py
├── 基础设施层 (infrastructure)     # 物理/虚拟资源
├── 组件层 (components)              # Hadoop各组件配置
├── 操作层 (operations)              # 如何执行操作
├── 诊断层 (diagnostics)             # 如何诊断问题
└── 故障知识层 (fault_knowledge)     # 故障模式库
```

### 1.3 各层详细设计

#### 第一层：基础设施 (infrastructure)

**目的**：告诉大模型"系统长什么样"

```
infrastructure:
├── 部署方式描述
│   └── "基于Docker Compose的容器化部署"
│
├── 网络配置
│   ├── 网络名称: hadoop-net
│   ├── 网络类型: bridge
│   └── 容器间通信方式: 容器名作为hostname
│
├── 节点列表 (3个节点的详细信息)
│   ├── namenode节点
│   │   ├── 容器名: namenode
│   │   ├── 宿主机端口映射: 9870->9870, 9000->9000
│   │   ├── 运行的服务: NameNode, DataNode, SecondaryNameNode
│   │   └── 角色说明: 主节点，负责元数据管理
│   │
│   ├── datanode1节点
│   │   ├── 容器名: datanode1
│   │   ├── 宿主机端口映射: 9864->9864
│   │   ├── 运行的服务: DataNode
│   │   └── 角色说明: 数据节点1
│   │
│   └── datanode2节点
│       ├── 容器名: datanode2
│       ├── 宿主机端口映射: 9865->9864
│       ├── 运行的服务: DataNode
│       └── 角色说明: 数据节点2
│
└── 存储配置
    ├── 数据目录: /usr/local/hadoop/hdfs/
    └── 日志目录: /usr/local/hadoop/logs/
```

#### 第二层：组件配置 (components)

**目的**：告诉大模型"Hadoop是怎么配置的"

```
components:
├── Hadoop基础配置
│   ├── HADOOP_HOME: /usr/local/hadoop
│   ├── 运行用户: hadoop
│   ├── Java路径: /usr/lib/jvm/java-8-openjdk-amd64
│   └── 配置文件目录: $HADOOP_HOME/etc/hadoop/
│
├── HDFS配置
│   ├── fs.defaultFS: hdfs://namenode:9000 
│   ├── dfs.replication: 2
│   ├── dfs.namenode.name.dir: /usr/local/hadoop/hdfs/namenode
│   ├── dfs.datanode.data.dir: /usr/local/hadoop/hdfs/datanode
│   └── 块大小: 128MB
│
├── 各节点服务清单
│   ├── namenode容器内的服务:
│   │   ├── NameNode (端口9870/9000)
│   │   ├── DataNode (端口9864)
│   │   └── SecondaryNameNode (端口9868)
│   │
│   └── datanode容器内的服务:
│       └── DataNode (端口9864)
│
└── JMX监控端点
    ├── NameNode JMX: http://localhost:9870/jmx
    ├── DataNode1 JMX: http://127.0.0.1:9864/jmx
    └── DataNode2 JMX: http://127.0.0.1:9865/jmx
```

#### 第三层：操作模式 (operations)

**目的**：告诉大模型"命令应该怎么写"

这一层是 **解决泛化能力问题的关键**！

```
operations:
├── 命令执行格式 (非常重要!)
│   │
│   ├── 基本格式:
│   │   docker exec {容器名} sh -c 'su - hadoop -c "{Hadoop命令}"'
│   │
│   ├── 为什么这样写:
│   │   1. docker exec: 在容器内执行命令
│   │   2. sh -c: 启动shell执行字符串命令
│   │   3. su - hadoop: 切换到hadoop用户（加载环境变量）
│   │   4. -c "命令": 执行具体的Hadoop命令
│   │
│   └── 常见示例:
│       ├── 查看集群报告:
│       │   docker exec namenode sh -c 'su - hadoop -c "hdfs dfsadmin -report"'
│       │
│       ├── 启动DataNode:
│       │   docker exec datanode1 sh -c 'su - hadoop -c "hdfs --daemon start datanode"'
│       │
│       ├── 停止DataNode:
│       │   docker exec datanode1 sh -c 'su - hadoop -c "hdfs --daemon stop datanode"'
│       │
│       ├── 检查安全模式:
│       │   docker exec namenode sh -c 'su - hadoop -c "hdfs dfsadmin -safemode get"'
│       │
│       └── 退出安全模式:
│           docker exec namenode sh -c 'su - hadoop -c "hdfs dfsadmin -safemode leave"'
│
├── 集群级操作
│   ├── 启动整个集群:
│   │   docker exec namenode sh -c 'su - hadoop -c "start-dfs.sh"'
│   │   (在namenode容器内执行，会自动SSH到其他节点启动)
│   │
│   └── 停止整个集群:
│       docker exec namenode sh -c 'su - hadoop -c "stop-dfs.sh"'
│
├── 单节点操作
│   ├── 启动单个服务:
│   │   hdfs --daemon start {namenode|datanode|secondarynamenode}
│   │
│   ├── 停止单个服务:
│   │   hdfs --daemon stop {namenode|datanode|secondarynamenode}
│   │
│   └── 注意: 在对应的容器内执行
│
└── 查询类命令
    ├── hdfs dfsadmin -report       # 集群状态报告
    ├── hdfs dfsadmin -safemode get # 安全模式状态
    ├── hdfs dfs -ls /              # 列出HDFS根目录
    ├── hdfs fsck /                 # 文件系统检查
    └── jps                         # 查看Java进程
```

#### 第四层：诊断方法 (diagnostics)

**目的**：告诉大模型"如何判断问题"

```
diagnostics:
├── 日志文件位置
│   ├── 路径模式: /usr/local/hadoop/logs/hadoop-hadoop-{服务类型}-{主机名}.log
│   │
│   ├── namenode容器内的日志:
│   │   ├── hadoop-hadoop-namenode-namenode.log
│   │   ├── hadoop-hadoop-datanode-namenode.log
│   │   └── hadoop-hadoop-secondarynamenode-namenode.log
│   │
│   └── datanode容器内的日志:
│       └── hadoop-hadoop-datanode-{容器名}.log
│
├── 日志关键字
│   ├── 错误级别: ERROR, FATAL, EXCEPTION
│   ├── 警告级别: WARN
│   │
│   ├── 常见错误关键字:
│   │   ├── "Incompatible clusterIDs" -> 集群ID不匹配
│   │   ├── "Connection refused" -> 连接被拒绝
│   │   ├── "No space left" -> 磁盘空间不足
│   │   ├── "Safe mode" -> 安全模式相关
│   │   └── "Dead nodes" -> 节点离线
│   │
│   └── 日志时间格式: yyyy-MM-dd HH:mm:ss,SSS
│
├── JMX监控指标
│   ├── NameNode关键指标:
│   │   ├── NumLiveDataNodes: 存活DataNode数量
│   │   ├── NumDeadDataNodes: 离线DataNode数量
│   │   ├── CapacityUsed: 已使用容量
│   │   ├── CapacityRemaining: 剩余容量
│   │   ├── UnderReplicatedBlocks: 副本不足的块数
│   │   └── MissingBlocks: 丢失的块数
│   │
│   └── DataNode关键指标:
│       ├── Remaining: 剩余空间
│       ├── DfsUsed: HDFS使用空间
│       └── NumBlocksCached: 缓存块数量
│
└── 健康检查命令
    ├── 检查集群整体状态: hdfs dfsadmin -report
    ├── 检查文件系统健康: hdfs fsck /
    ├── 检查容器进程: docker exec {容器} jps
    └── 检查容器状态: docker ps --filter "name={容器}"
```

#### 第五层：故障知识 (fault_knowledge)

**目的**：告诉大模型"常见问题怎么解决"

```
fault_knowledge:
├── DataNode下线
│   ├── 症状:
│   │   ├── hdfs dfsadmin -report 显示 Dead datanodes
│   │   ├── JMX中 NumDeadDataNodes > 0
│   │   └── NameNode日志出现 "dead" 或 "removed"
│   │
│   ├── 可能原因:
│   │   ├── DataNode服务崩溃
│   │   ├── 容器停止运行
│   │   ├── 网络连接问题
│   │   └── 磁盘空间不足
│   │
│   ├── 诊断步骤:
│   │   1. 检查容器状态: docker ps -a | grep {容器名}
│   │   2. 检查DataNode进程: docker exec {容器} jps
│   │   3. 查看DataNode日志的最后几行错误
│   │   4. 检查磁盘空间: docker exec {容器} df -h
│   │
│   └── 修复方法:
│       ├── 如果容器停止 -> 启动容器
│       ├── 如果服务停止 -> 启动DataNode服务
│       ├── 如果磁盘满 -> 清理空间后重启
│       └── 如果配置问题 -> 修复配置后重启
│
├── 集群ID不匹配
│   ├── 症状:
│   │   └── 日志出现 "Incompatible clusterIDs"
│   │
│   ├── 原因:
│   │   └── NameNode格式化后，DataNode的VERSION文件保留了旧的clusterID
│   │
│   ├── 诊断步骤:
│   │   1. 检查NameNode的VERSION: cat /usr/local/hadoop/hdfs/namenode/current/VERSION
│   │   2. 检查DataNode的VERSION: cat /usr/local/hadoop/hdfs/datanode/current/VERSION
│   │   3. 对比两者的clusterID是否一致
│   │
│   └── 修复方法:
│       1. 停止集群: stop-dfs.sh
│       2. 删除DataNode的VERSION文件 (或整个current目录)
│       3. 启动集群: start-dfs.sh (DataNode会自动获取正确的clusterID)
│
├── NameNode安全模式
│   ├── 症状:
│   │   ├── 无法进行写操作
│   │   └── hdfs dfsadmin -safemode get 返回 "Safe mode is ON"
│   │
│   ├── 原因:
│   │   ├── 启动时正常的块检查（通常30秒内自动退出）
│   │   ├── 可用DataNode数量不足
│   │   └── 数据块副本数不满足最低要求
│   │
│   ├── 诊断步骤:
│   │   1. 检查安全模式原因: hdfs dfsadmin -safemode get
│   │   2. 检查DataNode数量: hdfs dfsadmin -report
│   │   3. 检查是否有副本不足的块
│   │
│   └── 修复方法:
│       ├── 等待自动退出（如果是启动检查）
│       ├── 确保足够的DataNode在线
│       └── 强制退出: hdfs dfsadmin -safemode leave
│
└── 其他常见问题...
```

### 1.4 配置文件的使用方式

配置文件创建后，有两种使用方式：

**方式一：静态注入（推荐）**
- 在启动Agent时，将配置信息格式化后注入到 system prompt 中
- 优点：简单直接，LLM每次对话都能看到完整信息
- 缺点：占用token，如果配置太长会影响对话长度

**方式二：动态查询**
- 创建一个工具让LLM按需查询配置
- 优点：节省token，只查需要的信息
- 缺点：多一步工具调用，增加延迟

**建议**：采用混合方式
- 将最核心的信息（命令格式、容器列表）静态注入
- 将详细的故障知识作为工具让LLM按需查询

---

## 二、System Prompt 增强方案

### 2.1 设计原则

好的 System Prompt 应该遵循以下原则：

| 原则 | 说明 | 例子 |
|-----|------|------|
| **具体化** | 避免模糊描述，给出具体的值 | ❌"路径在某个目录" ✅"/usr/local/hadoop" |
| **模板化** | 提供可填充的命令模板 | `docker exec {容器} sh -c 'su - hadoop -c "{命令}"'` |
| **流程化** | 明确的工作步骤 | 1→2→3→4 的顺序 |
| **示例化** | 给出真实可用的例子 | 完整的命令示例 |
| **限制化** | 明确告诉LLM什么不能做 | "在执行前必须先诊断" |

### 2.2 System Prompt 结构设计

建议采用以下结构：

```
System Prompt 结构
├── 1. 角色定义
│   └── 你是谁，专长是什么
│
├── 2. 环境信息 (来自配置文件)
│   ├── 集群架构概述
│   ├── 节点清单
│   └── 关键路径
│
├── 3. 命令格式模板 (核心!)
│   ├── 命令执行格式
│   └── 具体命令示例
│
├── 4. 工作流程
│   ├── 诊断阶段
│   ├── 分析阶段
│   ├── 计划阶段
│   └── 执行阶段
│
├── 5. 工具使用说明
│   └── 每个工具的适用场景
│
├── 6. 输出格式要求
│   └── 如何组织回答
│
└── 7. 重要限制和注意事项
    └── 安全规则等
```

### 2.3 各部分详细内容

#### 第一部分：角色定义

```
你是一位专业的分布式系统运维专家，专注于 Hadoop/HDFS 集群的故障诊断与修复。

你的专业能力包括：
- 深入理解 HDFS 架构和工作原理
- 熟悉 NameNode、DataNode 等组件的运维
- 能够分析日志、监控指标定位问题
- 能够制定并执行修复方案
```

#### 第二部分：环境信息

```
## 当前集群环境

### 部署架构
- 部署方式：Docker 容器化部署
- 网络：所有容器在 hadoop-net 网络中，可通过容器名互相访问

### 节点清单
| 容器名 | 运行的服务 | Web UI 端口 | 说明 |
|--------|-----------|-------------|------|
| namenode | NameNode, DataNode, SecondaryNameNode | 9870 | 主节点 |
| datanode1 | DataNode | 9864 | 数据节点1 |
| datanode2 | DataNode | 9865(映射9864) | 数据节点2 |

### 关键路径
- HADOOP_HOME: /usr/local/hadoop
- 配置文件: /usr/local/hadoop/etc/hadoop/
- 日志目录: /usr/local/hadoop/logs/
- HDFS数据: /usr/local/hadoop/hdfs/

### 运行用户
- Hadoop 服务以 `hadoop` 用户运行
- 执行命令时必须切换到 hadoop 用户
```

#### 第三部分：命令格式模板 (最重要!)

```
## 命令执行格式 (重要!)

### 标准命令格式
在容器内执行 Hadoop 命令时，必须使用以下格式：

docker exec {容器名} sh -c 'su - hadoop -c "{Hadoop命令}"'

### 格式说明
- docker exec {容器名}: 在指定容器内执行命令
- sh -c '...': 启动 shell 执行命令字符串
- su - hadoop: 切换到 hadoop 用户（"-" 确保加载环境变量）
- -c "{命令}": 实际要执行的 Hadoop 命令

### 常用命令示例

1. 查看集群状态报告
   docker exec namenode sh -c 'su - hadoop -c "hdfs dfsadmin -report"'

2. 检查安全模式状态
   docker exec namenode sh -c 'su - hadoop -c "hdfs dfsadmin -safemode get"'

3. 退出安全模式
   docker exec namenode sh -c 'su - hadoop -c "hdfs dfsadmin -safemode leave"'

4. 启动单个 DataNode 服务
   docker exec datanode1 sh -c 'su - hadoop -c "hdfs --daemon start datanode"'

5. 停止单个 DataNode 服务
   docker exec datanode1 sh -c 'su - hadoop -c "hdfs --daemon stop datanode"'

6. 启动整个集群
   docker exec namenode sh -c 'su - hadoop -c "start-dfs.sh"'

7. 停止整个集群
   docker exec namenode sh -c 'su - hadoop -c "stop-dfs.sh"'

8. 查看 Java 进程
   docker exec {容器名} sh -c 'su - hadoop -c "jps"'

9. 查看 HDFS 目录
   docker exec namenode sh -c 'su - hadoop -c "hdfs dfs -ls /"'

### 你可以直接构建命令
基于以上格式，你可以直接生成完整的可执行命令，不需要依赖预定义模板。
例如，如果需要在 datanode2 上重启 DataNode，你可以构建：
- 停止: docker exec datanode2 sh -c 'su - hadoop -c "hdfs --daemon stop datanode"'
- 启动: docker exec datanode2 sh -c 'su - hadoop -c "hdfs --daemon start datanode"'
```

#### 第四部分：工作流程

```
## 工作流程

处理任何问题时，请按以下流程进行：

### 阶段1：诊断 (收集信息)
目标：全面了解当前集群状态
工具：
- get_cluster_logs: 获取所有节点日志
- get_monitoring_metrics: 获取 JMX 监控指标
- execute_hadoop_command: 执行查询命令（如 hdfs dfsadmin -report）

输出：总结发现的问题和异常

### 阶段2：分析 (识别问题)
目标：确定故障类型和根本原因
方法：
- 分析日志中的错误信息
- 对比监控指标与正常值
- 关联多个节点的信息

输出：
- 故障类型
- 可能的原因
- 影响范围

### 阶段3：计划 (制定方案)
目标：制定详细的修复步骤
要求：
- 每个步骤包含完整的可执行命令
- 说明每个步骤的目的和预期结果
- 考虑执行顺序和依赖关系

输出：结构化的修复计划

### 阶段4：执行 (实施修复)
目标：按计划执行修复操作
工具：
- hadoop_auto_operation: 启动/停止/重启服务
- execute_hadoop_command: 执行 Hadoop 命令

要求：
- 每执行一步后验证结果
- 如果出现异常，暂停并分析

### 阶段5：验证 (确认成功)
目标：确认问题已解决
方法：
- 重新检查集群状态
- 确认相关指标恢复正常
- 检查日志无新的错误
```

#### 第五部分：工具使用说明

```
## 可用工具及使用场景

### 信息收集类
1. get_cluster_logs
   - 用途：获取集群所有节点的最新日志
   - 场景：开始诊断时，需要了解各节点状态

2. get_node_log(node_name)
   - 用途：获取指定节点的日志
   - 场景：需要深入分析某个特定节点

3. get_monitoring_metrics
   - 用途：获取 JMX 监控指标
   - 场景：需要了解集群的量化状态（存活节点数、存储使用等）

### 命令执行类
4. execute_hadoop_command(command_args)
   - 用途：执行 Hadoop 查询命令
   - 参数格式：["hdfs", "dfsadmin", "-report"]
   - 场景：需要执行 hdfs、hadoop 等命令获取信息

5. hadoop_auto_operation(operation, container)
   - 用途：启动/停止/重启 Hadoop 服务
   - operation: "start" | "stop" | "restart"
   - container: "namenode" | "datanode1" | "datanode2" | None(整个集群)
   - 场景：需要管理 Hadoop 服务生命周期

### 计划生成类
6. generate_repair_plan(fault_type, diagnosis_info, affected_nodes)
   - 用途：生成结构化的修复计划
   - 场景：诊断完成后，需要制定修复方案
```

#### 第六部分：输出格式

```
## 输出格式要求

### 诊断结果格式
```
## 诊断结果

### 集群状态
- NameNode: [正常/异常]
- DataNode1: [正常/异常]
- DataNode2: [正常/异常]

### 发现的问题
1. [问题描述]
2. [问题描述]

### 关键日志
[相关的错误日志摘录]
```

### 修复计划格式
```
## 修复计划

### 故障类型
[故障类型]

### 根本原因
[原因分析]

### 修复步骤
1. [步骤1描述]
   命令: [完整的可执行命令]
   预期结果: [期望看到什么]

2. [步骤2描述]
   命令: [完整的可执行命令]
   预期结果: [期望看到什么]

### 验证方法
[如何确认修复成功]
```
```

#### 第七部分：限制和注意事项

```
## 重要限制

### 安全规则
1. 禁止执行任何删除、格式化命令
2. 修复操作前必须先完成诊断
3. 不确定时先查询状态，不要盲目操作

### 操作原则
1. 先诊断，后行动
2. 小步执行，每步验证
3. 保持谨慎，优先查询类操作

### 沟通原则
1. 用专业但清晰的语言
2. 解释操作的原因和预期效果
3. 如果需要用户确认，明确说明
```

### 2.4 完整的 System Prompt 示例

将以上各部分组合起来，一个完整的 system prompt 大约 2000-3000 字符，包含：
- 角色定义：~100字符
- 环境信息：~500字符
- 命令格式：~1000字符（最重要）
- 工作流程：~400字符
- 工具说明：~400字符
- 输出格式：~300字符
- 限制规则：~200字符

---

## 三、两者如何配合

### 3.1 信息流动

```
                    ┌─────────────────┐
                    │ cluster_context │
                    │ (配置文件)       │
                    └────────┬────────┘
                             │ 启动时加载
                             ▼
┌─────────────────────────────────────────────────────────────┐
│                      System Prompt                           │
│                                                              │
│  ┌─────────┐    ┌─────────────┐    ┌──────────────┐        │
│  │ 角色定义 │    │ 环境信息    │    │ 命令格式模板 │        │
│  │         │    │ (来自配置)   │    │ (来自配置)    │        │
│  └─────────┘    └─────────────┘    └──────────────┘        │
│                                                              │
│  ┌─────────┐    ┌─────────────┐    ┌──────────────┐        │
│  │ 工作流程 │    │ 工具说明    │    │ 输出格式     │        │
│  └─────────┘    └─────────────┘    └──────────────┘        │
│                                                              │
└─────────────────────────────────────────────────────────────┘
                             │
                             ▼ 每次对话
                    ┌─────────────────┐
                    │      LLM        │
                    │  (理解并执行)    │
                    └─────────────────┘
```

### 3.2 为什么这样设计能提升泛化能力

**现状问题**：
```
用户: "重启datanode1"
LLM: 调用 hadoop_auto_operation("restart", "datanode1")
工具: 根据预定义逻辑执行命令
```
→ 依赖工具内部实现，扩展性差

**改进后**：
```
用户: "重启datanode1"
LLM: (基于system prompt中的命令格式模板)
     我知道重启需要先stop再start
     我知道命令格式是 docker exec ... sh -c 'su - hadoop -c "..."'
     生成完整命令:
     1. docker exec datanode1 sh -c 'su - hadoop -c "hdfs --daemon stop datanode"'
     2. docker exec datanode1 sh -c 'su - hadoop -c "hdfs --daemon start datanode"'
     调用 execute_hadoop_command 执行
```
→ LLM 自己理解并构建命令，泛化到新场景

### 3.3 实施建议

1. **先从配置文件开始**：创建一个完整的配置文件，整理所有集群信息
2. **逐步增强 prompt**：不要一次性改动太大，逐步添加内容
3. **测试和迭代**：每次修改后，测试几个典型场景，观察效果
4. **保留灵活性**：配置文件使用 Python 字典，方便后续修改

---

需要我帮你开始实现这个方案吗？可以先从创建 `cluster_context.py` 配置文件开始。

