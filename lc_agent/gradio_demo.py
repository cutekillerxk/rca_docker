#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HDFS é›†ç¾¤ç›‘æ§ Agent - Gradio Web ç•Œé¢ç‰ˆæœ¬ï¼ˆLangChain + vLLMï¼‰
åŸºäº LangChain å’Œ vLLM å®ç°è‡ªä¸»å·¥å…·è°ƒç”¨çš„ Agent

ä½¿ç”¨æ–¹æ³•ï¼š

       python lc_agent/agentt_gradio.py
    
     åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æ˜¾ç¤ºçš„ URLï¼ˆé€šå¸¸æ˜¯ http://127.0.0.1:7860ï¼‰
"""

import gradio as gr
import sys
import os
import signal
import atexit

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥ç°æœ‰æ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥ LangChain Agent
from lc_agent.agent import create_agent_instance, export_to_word, export_to_pdf
from lc_agent.monitor_collector import collect_all_metrics, format_metrics_for_display

# å…¨å±€ Agent å®ä¾‹å’Œå½“å‰æ¨¡å‹
agent = None
current_model = "qwen-8b"  # å½“å‰ä½¿ç”¨çš„æ¨¡å‹
# å­˜å‚¨æœ€åä¸€æ¬¡çš„Agentå›å¤ï¼ˆç”¨äºæ–‡æ¡£å¯¼å‡ºï¼‰
last_agent_response = ""
# å…¨å±€ Gradio demo å®ä¾‹ï¼ˆç”¨äºä¼˜é›…å…³é—­ï¼‰
demo_instance = None
# å…³é—­æ ‡å¿—ï¼Œé˜²æ­¢é‡å¤å…³é—­
_shutting_down = False

# æ¨¡å‹åç§°æ˜ å°„ï¼ˆå‰ç«¯æ˜¾ç¤ºåç§° -> å†…éƒ¨æ¨¡å‹åç§°ï¼‰
MODEL_NAME_MAP = {
    "Qwen-8B (vLLM)": "qwen-8b",
    "GPT-4o (OpenAI)": "gpt-4o",
    "DeepSeek-R1 (DeepSeek)": "deepseek-r1"
}


def init_agent(model_name: str = "qwen-8b"):
    """
    åˆå§‹åŒ– LangChain Agentï¼ˆæ”¯æŒæ¨¡å‹åˆ‡æ¢ï¼‰
    
    Args:
        model_name: æ¨¡å‹åç§°ï¼Œå¯é€‰å€¼ï¼šqwen-8b, gpt-4o, deepseek-r1
    """
    global agent, current_model
    
    model_display_name = {v: k for k, v in MODEL_NAME_MAP.items()}.get(model_name, model_name)
    
    # å¦‚æœæ¨¡å‹æ”¹å˜æˆ–Agentæœªåˆå§‹åŒ–ï¼Œé‡æ–°åˆ›å»ºAgent
    if agent is None:
        print(f"[INFO] Agentæœªåˆå§‹åŒ–ï¼Œæ­£åœ¨åˆ›å»ºæ–°Agentï¼ˆæ¨¡å‹: {model_display_name}ï¼‰...")
        try:
            agent = create_agent_instance(model_name)
            if agent is None:
                raise RuntimeError("LangChain Agent åˆå§‹åŒ–å¤±è´¥")
            current_model = model_name
            print(f"[INFO] âœ… LangChain Agent åˆå§‹åŒ–å®Œæˆï¼ˆæ¨¡å‹: {model_display_name}ï¼‰")
            print(f"[DEBUG] å½“å‰æ¨¡å‹çŠ¶æ€: current_model = '{current_model}'")
        except Exception as e:
            error_msg = f"LangChain Agent åˆå§‹åŒ–å¤±è´¥: {str(e)}"
            print(f"[ERROR] {error_msg}")
            print("[æç¤º] è¯·æ£€æŸ¥ï¼š")
            if model_name == "qwen-8b":
                print("[æç¤º]   1. vLLM æœåŠ¡æ˜¯å¦å·²å¯åŠ¨")
                print("[æç¤º]   2. æœåŠ¡åœ°å€æ˜¯å¦æ­£ç¡®")
                print("[æç¤º]   3. æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®")
            else:
                print(f"[æç¤º]   1. ç¬¬ä¸‰æ–¹APIé…ç½®æ˜¯å¦æ­£ç¡®ï¼ˆAPI_BASE_URL, API_KEYï¼‰")
                print(f"[æç¤º]   2. æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®")
                print(f"[æç¤º]   3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
            raise RuntimeError(error_msg)
    elif current_model != model_name:
        print(f"[INFO] æ£€æµ‹åˆ°æ¨¡å‹åˆ‡æ¢è¯·æ±‚:")
        print(f"[INFO]   å½“å‰æ¨¡å‹: {current_model} ({MODEL_NAME_MAP.get(current_model, current_model)})")
        print(f"[INFO]   ç›®æ ‡æ¨¡å‹: {model_name} ({model_display_name})")
        print(f"[INFO] æ­£åœ¨é‡æ–°åˆ›å»ºAgent...")
        try:
            agent = create_agent_instance(model_name)
            if agent is None:
                raise RuntimeError("LangChain Agent åˆå§‹åŒ–å¤±è´¥")
            old_model = current_model
            current_model = model_name
            print(f"[INFO] âœ… æ¨¡å‹åˆ‡æ¢æˆåŠŸ:")
            print(f"[INFO]   ä»: {old_model} ({MODEL_NAME_MAP.get(old_model, old_model)})")
            print(f"[INFO]   åˆ°: {current_model} ({model_display_name})")
            print(f"[DEBUG] å½“å‰æ¨¡å‹çŠ¶æ€: current_model = '{current_model}'")
        except Exception as e:
            error_msg = f"æ¨¡å‹åˆ‡æ¢å¤±è´¥: {str(e)}"
            print(f"[ERROR] {error_msg}")
            print(f"[ERROR] ä¿æŒä½¿ç”¨åŸæ¨¡å‹: {current_model}")
            print("[æç¤º] è¯·æ£€æŸ¥ï¼š")
            if model_name == "qwen-8b":
                print("[æç¤º]   1. vLLM æœåŠ¡æ˜¯å¦å·²å¯åŠ¨")
                print("[æç¤º]   2. æœåŠ¡åœ°å€æ˜¯å¦æ­£ç¡®")
                print("[æç¤º]   3. æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®")
            else:
                print(f"[æç¤º]   1. ç¬¬ä¸‰æ–¹APIé…ç½®æ˜¯å¦æ­£ç¡®ï¼ˆAPI_BASE_URL, API_KEYï¼‰")
                print(f"[æç¤º]   2. æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®")
                print(f"[æç¤º]   3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
            raise RuntimeError(error_msg)
    else:
        print(f"[DEBUG] ä½¿ç”¨ç°æœ‰Agentï¼ˆæ¨¡å‹: {model_display_name}ï¼Œcurrent_model = '{current_model}'ï¼‰")
    
    return agent


def update_monitoring_display():
    """æ›´æ–°ç›‘æ§æ•°æ®æ˜¾ç¤º"""
    try:
        metrics_data = collect_all_metrics()
        html_content = format_metrics_for_display(metrics_data)
        return html_content
    except Exception as e:
        error_html = f"<div style='color: red; padding: 20px;'>âŒ è·å–ç›‘æ§æ•°æ®å¤±è´¥: {str(e)}</div>"
        return error_html


def create_gradio_interface():
    """åˆ›å»º Gradio ç•Œé¢"""
    
    # è‡ªå®šä¹‰ CSS æ ·å¼ï¼ˆå¯é€‰ï¼Œè®©ç•Œé¢æ›´ç¾è§‚ï¼‰
    custom_css = """
    .gradio-container {
        font-family: 'Microsoft YaHei', 'PingFang SC', Arial, sans-serif;
    }
    .chat-message {
        padding: 10px;
    }
    """
    
    # ä½¿ç”¨ Blocks åˆ›å»ºæ›´çµæ´»çš„å¸ƒå±€
    with gr.Blocks(title="HDFS é›†ç¾¤ç›‘æ§ Agent (LangChain + vLLM)", theme=gr.themes.Soft(), css=custom_css) as demo:
        # ä½¿ç”¨ä¸¤åˆ—å¸ƒå±€ï¼šå·¦ä¾§ï¼ˆæ ‡é¢˜+ç›‘æ§ï¼‰ï¼Œå³ä¾§ï¼ˆèŠå¤©ï¼‰
        with gr.Row():
            # å·¦ä¾§åˆ—ï¼šæ ‡é¢˜+åŠŸèƒ½è¯´æ˜ + ç›‘æ§æ•°æ®
            with gr.Column(scale=1, min_width=300):
                # æ ‡é¢˜å’ŒåŠŸèƒ½è¯´æ˜ï¼ˆæ”¾åœ¨å·¦ä¾§åˆ—å†…éƒ¨ï¼‰
                gr.Markdown("""
                #  HDFS é›†ç¾¤ç›‘æ§æ™ºèƒ½åŠ©æ‰‹
                
                **åŠŸèƒ½è¯´æ˜**ï¼š
                - ğŸ“Š **å®æ—¶ç›‘æ§**ï¼šæ˜¾ç¤ºé›†ç¾¤å…³é”®æŒ‡æ ‡
                - ğŸ’¬ **æ™ºèƒ½å¯¹è¯**ï¼šå¯ä»¥å›ç­”å…³äº HDFS é›†ç¾¤çš„é—®é¢˜
                - ğŸ” **è‡ªä¸»å·¥å…·è°ƒç”¨**ï¼šæ™ºèƒ½ç†è§£ç”¨æˆ·æ„å›¾ï¼Œè‡ªä¸»è°ƒç”¨å·¥å…·åˆ†æé›†ç¾¤æ—¥å¿—
                - ğŸ¤– **å¤šæ¨¡å‹æ”¯æŒ**ï¼šæ”¯æŒåˆ‡æ¢ Qwen-8Bã€GPT-4oã€DeepSeek-R1
                
                **å¯ç”¨å·¥å…·**ï¼š
                - æ£€æŸ¥é›†ç¾¤çŠ¶æ€
                - è·å–ç›‘æ§æŒ‡æ ‡
                - åˆ†ææŒ‡å®šèŠ‚ç‚¹æ—¥å¿—
                """)
                
                gr.Markdown("### ğŸ“Š é›†ç¾¤ç›‘æ§æŒ‡æ ‡")
                monitoring_html = gr.HTML(
                    value="<div style='padding: 20px; text-align: center;'>æ­£åœ¨åŠ è½½ç›‘æ§æ•°æ®...</div>",
                    label="ç›‘æ§æ•°æ®",
                    elem_id="monitoring-display"
                )
                
                # åˆ·æ–°æŒ‰é’®
                refresh_btn = gr.Button("ğŸ”„ æ‰‹åŠ¨åˆ·æ–°", variant="primary", size="sm")
                
                def refresh_monitoring():
                    """æ‰‹åŠ¨åˆ·æ–°ç›‘æ§æ•°æ®""" 
                    return update_monitoring_display()
                
                refresh_btn.click(
                    fn=refresh_monitoring,
                    inputs=None,
                    outputs=monitoring_html
                )
                
                # å¯¼å‡ºæŒ‰é’®ï¼ˆä¸¤ä¸ªæŒ‰é’®åŒè¡Œï¼Œå®½åº¦åŠ èµ·æ¥ç­‰äºåˆ·æ–°æŒ‰é’®ï¼‰
                with gr.Row():
                    export_word_btn = gr.Button("ğŸ“„ å¯¼å‡ºWord", variant="secondary", size="sm", scale=1)
                    export_pdf_btn = gr.Button("ğŸ“„ å¯¼å‡ºPDF", variant="secondary", size="sm", scale=1)
                
                # å¯¼å‡ºçŠ¶æ€ï¼ˆæ”¾åœ¨æŒ‰é’®ä¸‹æ–¹ï¼‰
                export_status = gr.Textbox(
                    label="å¯¼å‡ºçŠ¶æ€",
                    visible=True,
                    interactive=False,
                    lines=2
                )
                
                # æ–‡ä»¶ä¸‹è½½ç»„ä»¶ï¼ˆç”¨äºè§¦å‘æµè§ˆå™¨ä¸‹è½½ï¼‰
                # è®¾ç½®ä¸ºå¯è§ä½†æ ·å¼æœ€å°åŒ–ï¼Œç”¨æˆ·å¯ä»¥çœ‹åˆ°ä¸‹è½½é“¾æ¥
                export_file = gr.File(
                    label="ä¸‹è½½æ–‡ä»¶",
                    visible=True,
                    interactive=False,
                    height=50  # è®¾ç½®è¾ƒå°çš„é«˜åº¦
                )
                
                # æ·»åŠ è‡ªå®šä¹‰JavaScriptï¼Œå®ç°è‡ªåŠ¨ä¸‹è½½
                download_js = """
                function(file) {
                    if (file) {
                        // åˆ›å»ºéšè—çš„ä¸‹è½½é“¾æ¥å¹¶è‡ªåŠ¨ç‚¹å‡»
                        const link = document.createElement('a');
                        link.href = file;
                        link.download = file.split('/').pop() || 'download';
                        link.style.display = 'none';
                        document.body.appendChild(link);
                        link.click();
                        document.body.removeChild(link);
                    }
                    return file;
                }
                """
            
            # å³ä¾§åˆ—ï¼šèŠå¤©å¯¹è¯ï¼ˆæ›´å¤šç©ºé—´ï¼‰
            with gr.Column(scale=2, min_width=400):
                gr.Markdown("### ğŸ’¬ æ™ºèƒ½å¯¹è¯ï¼ˆè‡ªä¸»å·¥å…·è°ƒç”¨ï¼‰")
                
                # æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
                model_selector = gr.Dropdown(
                    choices=list(MODEL_NAME_MAP.keys()),
                    value="Qwen-8B (vLLM)",
                    label="é€‰æ‹©å¤§æ¨¡å‹",
                    info="åˆ‡æ¢ä¸åŒçš„å¤§æ¨¡å‹è¿›è¡Œå¯¹è¯",
                    interactive=True
                )
                
                # ä½¿ç”¨æ–°æ ¼å¼ï¼ˆmessagesï¼‰ï¼Œå…¼å®¹ Gradio 4.0+
                # æ³¨æ„ï¼šå¦‚æœä½¿ç”¨ type='messages'ï¼Œéœ€è¦ä¿®æ”¹æ¶ˆæ¯æ ¼å¼å¤„ç†
                # ä¸ºäº†å…¼å®¹æ€§ï¼Œæš‚æ—¶ä¿æŒ tuples æ ¼å¼ï¼Œä½†æ·»åŠ  type å‚æ•°ä»¥æ¶ˆé™¤è­¦å‘Š
                chatbot = gr.Chatbot(
                    label="å¯¹è¯å†å²",
                    height=500,
                    show_copy_button=True
                    # æ³¨æ„ï¼šä¿æŒtuplesæ ¼å¼ä»¥å…¼å®¹ç°æœ‰ä»£ç ï¼ŒGradioè­¦å‘Šå¯ä»¥å¿½ç•¥
                )
                msg = gr.Textbox(
                    label="è¾“å…¥æ¶ˆæ¯",
                    placeholder="è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œä¾‹å¦‚ï¼šæŸ¥çœ‹é›†ç¾¤çŠ¶æ€ã€æ£€æŸ¥ s2 èŠ‚ç‚¹ã€è·å–ç›‘æ§æŒ‡æ ‡ã€HDFS æ˜¯ä»€ä¹ˆï¼Ÿ",
                    lines=2
                )
                
                with gr.Row():
                    submit_btn = gr.Button("ğŸ“¤ å‘é€", variant="primary")
                    clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©º", variant="secondary")
                
                # ç¤ºä¾‹é—®é¢˜ï¼ˆå±•ç¤ºè‡ªä¸»å·¥å…·è°ƒç”¨èƒ½åŠ›ï¼‰
                gr.Examples(
                    examples=[
                        "å…³é—­èŠ‚ç‚¹datanode1",
                        "å¯åŠ¨èŠ‚ç‚¹datanode1",
                        "æŸ¥çœ‹é›†ç¾¤çŠ¶æ€",
                        "å…³é—­æ•´ä¸ªhadoopé›†ç¾¤",
                        "å¯åŠ¨æ•´ä¸ªhadoopé›†ç¾¤",
                        "NameNode çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ",
                    ],
                    inputs=msg
                )
        
        # æ¨¡å‹åˆ‡æ¢åŠŸèƒ½
        def switch_model(selected_model, chat_history):
            """åˆ‡æ¢æ¨¡å‹å¹¶æ¸…ç©ºå¯¹è¯å†å²"""
            global agent, current_model
            
            model_name = MODEL_NAME_MAP.get(selected_model, "qwen-8b")
            
            print(f"[DEBUG] ========== æ¨¡å‹åˆ‡æ¢è¯·æ±‚ ==========")
            print(f"[DEBUG] ç”¨æˆ·é€‰æ‹©: {selected_model}")
            print(f"[DEBUG] æ˜ å°„åˆ°å†…éƒ¨æ¨¡å‹å: {model_name}")
            print(f"[DEBUG] å½“å‰æ¨¡å‹: {current_model}")
            
            if current_model != model_name:
                print(f"[INFO] ğŸ”„ å¼€å§‹åˆ‡æ¢æ¨¡å‹: {current_model} -> {model_name}")
                try:
                    # é‡ç½® Agentï¼Œå¼ºåˆ¶é‡æ–°åˆ›å»º
                    print(f"[DEBUG] é‡ç½®Agentå®ä¾‹ï¼ˆagent = Noneï¼‰")
                    agent = None
                    # å°è¯•åˆå§‹åŒ–æ–°æ¨¡å‹ï¼ˆéªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®ï¼‰
                    print(f"[DEBUG] è°ƒç”¨ init_agent('{model_name}') åˆå§‹åŒ–æ–°æ¨¡å‹...")
                    init_agent(model_name)
                    print(f"[DEBUG] âœ… æ¨¡å‹åˆ‡æ¢å®Œæˆï¼Œæ¸…ç©ºå¯¹è¯å†å²")
                    # æ¸…ç©ºå¯¹è¯å†å²
                    return []
                except Exception as e:
                    error_msg = f"âŒ åˆ‡æ¢æ¨¡å‹å¤±è´¥: {str(e)}\nè¯·æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ API_BASE_URL å’Œ API_KEY é…ç½®"
                    print(f"[ERROR] {error_msg}")
                    print(f"[ERROR] æ¨¡å‹åˆ‡æ¢å¤±è´¥ï¼Œä¿æŒä½¿ç”¨åŸæ¨¡å‹: {current_model}")
                    # ä¿æŒå½“å‰å¯¹è¯å†å²ï¼Œåœ¨å¯¹è¯ä¸­æ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯
                    if chat_history:
                        chat_history.append(["", error_msg])
                    else:
                        chat_history = [["", error_msg]]
                    return chat_history
            else:
                print(f"[DEBUG] æ¨¡å‹æœªæ”¹å˜ï¼Œæ— éœ€åˆ‡æ¢ï¼ˆå½“å‰: {current_model}ï¼‰")
                return chat_history
        
        # ç»‘å®šæ¨¡å‹åˆ‡æ¢äº‹ä»¶
        model_selector.change(
            fn=switch_model,
            inputs=[model_selector, chatbot],
            outputs=[chatbot]  # åªæ›´æ–°å¯¹è¯å†å²
        )
        
        # èŠå¤©åŠŸèƒ½ï¼ˆä½¿ç”¨å…¼å®¹çš„ tuples æ ¼å¼ï¼‰
        def respond(message, chat_history, selected_model):
            """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
            global last_agent_response
            
            if not message.strip():
                return chat_history, ""
            
            # ç¬¬ä¸€æ­¥ï¼šç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯ï¼Œå¹¶æ˜¾ç¤º"æ­£åœ¨å¤„ç†..."æç¤º
            chat_history.append([message, "â³ æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™..."])
            yield chat_history, ""  # ç«‹å³è¿”å›ï¼Œè®©ç•Œé¢æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯å’Œå¤„ç†æç¤º
            
            # ç¬¬äºŒæ­¥ï¼šè·å– Agent å›å¤ï¼ˆæ­¤æ—¶ç”¨æˆ·æ¶ˆæ¯å’Œå¤„ç†æç¤ºå·²ç»æ˜¾ç¤ºï¼‰
            try:
                # æ ¹æ®é€‰æ‹©çš„æ¨¡å‹è·å–æˆ–åˆ›å»º Agent
                model_name = MODEL_NAME_MAP.get(selected_model, "qwen-8b")
                print(f"[DEBUG] ========== å¤„ç†ç”¨æˆ·æ¶ˆæ¯ ==========")
                print(f"[DEBUG] ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹: {selected_model} -> {model_name}")
                print(f"[DEBUG] è°ƒç”¨ init_agent('{model_name}') è·å–Agent...")
                current_agent = init_agent(model_name)
                print(f"[DEBUG] âœ… Agentè·å–æˆåŠŸï¼Œå¼€å§‹å¤„ç†æ¶ˆæ¯...")
                
                # ä½¿ç”¨æ–°çš„invokeæ–¹å¼è°ƒç”¨Agent
                config = {"configurable": {"thread_id": "gradio_chat"}}
                result = current_agent.invoke(
                    {"messages": [{"role": "user", "content": message}]},
                    config=config
                )
                
                # æå–å›å¤å†…å®¹
                # éœ€è¦æ‰¾åˆ°æœ€åä¸€æ¡AIæ¶ˆæ¯ï¼ˆä¸æ˜¯å·¥å…·è°ƒç”¨æ¶ˆæ¯ï¼‰
                response = ""
                
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                if "messages" in result:
                    for i, msg in enumerate(result["messages"]):
                        msg_type = None
                        if hasattr(msg, "type"):
                            msg_type = msg.type
                        elif isinstance(msg, dict):
                            msg_type = msg.get("type")
                
                if "messages" in result and len(result["messages"]) > 0:
                    # ä»åå¾€å‰æŸ¥æ‰¾æœ€åä¸€æ¡AIæ¶ˆæ¯
                    for msg in reversed(result["messages"]):
                        # æ£€æŸ¥æ¶ˆæ¯ç±»å‹
                        msg_type = None
                        msg_content = None
                        
                        if hasattr(msg, "type"):
                            msg_type = msg.type
                            msg_content = getattr(msg, "content", None)
                        elif isinstance(msg, dict):
                            msg_type = msg.get("type")
                            msg_content = msg.get("content")
                        else:
                            # å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                            msg_content = str(msg)
                        
                        # è·³è¿‡å·¥å…·è°ƒç”¨æ¶ˆæ¯å’Œå·¥å…·è¿”å›æ¶ˆæ¯
                        if msg_type in ["tool", "tool_call", "ToolMessage"]:
                            continue
                        
                        # å¦‚æœæ˜¯AIæ¶ˆæ¯ä¸”æœ‰å†…å®¹ï¼Œä½¿ç”¨å®ƒ
                        if msg_type in ["ai", "AIMessage"] or (msg_type is None and msg_content):
                            if msg_content:
                                response = msg_content if isinstance(msg_content, str) else str(msg_content)
                                break
                    
                    # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•ä½¿ç”¨æœ€åä¸€æ¡éå·¥å…·æ¶ˆæ¯
                    if not response:
                        for msg in reversed(result["messages"]):
                            msg_type = None
                            if hasattr(msg, "type"):
                                msg_type = msg.type
                            elif isinstance(msg, dict):
                                msg_type = msg.get("type")
                            
                            # è·³è¿‡å·¥å…·ç›¸å…³æ¶ˆæ¯
                            if msg_type in ["tool", "tool_call", "ToolMessage"]:
                                continue
                            
                            # å°è¯•æå–å†…å®¹
                            if hasattr(msg, "content"):
                                response = msg.content if isinstance(msg.content, str) else str(msg.content)
                            elif isinstance(msg, dict):
                                response = msg.get("content", str(msg))
                            else:
                                response = str(msg)
                            
                            if response:
                                break
                    
                    # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆå³ä½¿å¯èƒ½æ˜¯å·¥å…·æ¶ˆæ¯ï¼‰
                    if not response and len(result["messages"]) > 0:
                        last_msg = result["messages"][-1]
                        if hasattr(last_msg, "content"):
                            response = last_msg.content
                        elif isinstance(last_msg, dict):
                            response = last_msg.get("content", str(last_msg))
                        else:
                            response = str(last_msg)
                else:
                    response = str(result)
                
                # å¦‚æœå“åº”ä¸ºç©ºæˆ–åªåŒ…å«å·¥å…·è°ƒç”¨æ ¼å¼ï¼Œè¯´æ˜å¯èƒ½æœ‰é—®é¢˜
                if not response or (isinstance(response, str) and response.strip().startswith("{") and "name" in response and "arguments" in response):
                    error_msg = "âš ï¸ Agentè¿”å›äº†å·¥å…·è°ƒç”¨æ ¼å¼ï¼Œä½†æœªç”Ÿæˆæœ€ç»ˆå›å¤ã€‚å¯èƒ½åŸå› ï¼š\n1. Agentä»åœ¨å¤„ç†ä¸­ï¼ˆéœ€è¦å¤šæ¬¡æ€è€ƒï¼‰\n2. vLLMé…ç½®é—®é¢˜\n3. æ¨¡å‹è¾“å‡ºæ ¼å¼é”™è¯¯"
                    print(f"[ERROR] {error_msg}")
                    response = error_msg
                
                
                # ç¡®ä¿responseæ˜¯å­—ç¬¦ä¸²
                if not isinstance(response, str):
                    response = str(response)
                
                # æ¸…ç†vLLMæ¨ç†æ ‡è®°ï¼ˆå¦‚<think>ã€<think>ç­‰ï¼‰
                import re
                # ç§»é™¤å¸¸è§çš„æ¨ç†æ ‡è®°
                response = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL)
                response = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL)
                response = re.sub(r'<reasoning>.*?</reasoning>', '', response, flags=re.DOTALL)
                # ç§»é™¤å…¶ä»–å¯èƒ½çš„XMLæ ‡ç­¾ï¼ˆä½†ä¿ç•™å†…å®¹ï¼‰
                response = re.sub(r'<[^>]+>', '', response)
                
                # æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
                response = response.strip()
                
                # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©º
                if not response or not response.strip():
                    response = "âš ï¸ Agentè¿”å›äº†ç©ºå“åº”ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚"
                    print("[ERROR] Agentè¿”å›äº†ç©ºå“åº”")
                else:
                    print(f"[DEBUG] æ¸…ç†åå“åº”é•¿åº¦: {len(response)}")
                

                last_agent_response = response  # ä¿å­˜æœ€åä¸€æ¬¡å›å¤
                
                # ç¡®ä¿chat_historyæ ¼å¼æ­£ç¡®
                if len(chat_history) > 0:
                    # æ›´æ–°æœ€åä¸€æ¡æ¶ˆæ¯çš„AIå›å¤éƒ¨åˆ†
                    if isinstance(chat_history[-1], list) and len(chat_history[-1]) >= 2:
                        chat_history[-1][1] = response
                    elif isinstance(chat_history[-1], tuple) and len(chat_history[-1]) >= 2:
                        # å¦‚æœæ˜¯å…ƒç»„ï¼Œéœ€è¦è½¬æ¢ä¸ºåˆ—è¡¨
                        chat_history[-1] = [chat_history[-1][0], response]
                    else:
                        # å¦‚æœæ ¼å¼ä¸å¯¹ï¼Œé‡æ–°è®¾ç½®
                        chat_history[-1] = [message, response]
                    
                    print(f"[DEBUG] æ›´æ–°åchat_history[-1]: {chat_history[-1][0][:50] if len(chat_history[-1][0]) > 50 else chat_history[-1][0]}... -> {chat_history[-1][1][:50] if len(chat_history[-1][1]) > 50 else chat_history[-1][1]}...")
                else:
                    print("[ERROR] chat_historyä¸ºç©ºï¼Œæ— æ³•æ›´æ–°")
                    chat_history.append([message, response])
                
            except Exception as e:
                error_msg = f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}"
                last_agent_response = error_msg
                print(f"[ERROR] {error_msg}")
                import traceback
                traceback.print_exc()
                
                # ç¡®ä¿é”™è¯¯ä¿¡æ¯ä¹Ÿèƒ½æ˜¾ç¤º
                if len(chat_history) > 0:
                    if isinstance(chat_history[-1], list) and len(chat_history[-1]) >= 2:
                        chat_history[-1][1] = error_msg
                    else:
                        chat_history[-1] = [message, error_msg]
                else:
                    chat_history.append([message, error_msg])
            
            # ç¬¬ä¸‰æ­¥ï¼šè¿”å›å®Œæ•´çš„å¯¹è¯å†å²ï¼ˆåŒ…å« AI å›å¤ï¼‰

            yield chat_history, ""
        
        # æ–‡æ¡£å¯¼å‡ºåŠŸèƒ½
        def export_document(format_type: str):
            """å¯¼å‡ºæ–‡æ¡£å¹¶è¿”å›æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºæµè§ˆå™¨ä¸‹è½½ï¼‰"""
            global last_agent_response
            
            if not last_agent_response or last_agent_response.startswith("âŒ"):
                return None, "âŒ æ²¡æœ‰å¯å¯¼å‡ºçš„å†…å®¹ï¼Œè¯·å…ˆä¸Agentå¯¹è¯è·å–åˆ†æç»“æœ"
            
            try:
                from datetime import datetime
                import os
                
                # ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•ï¼ˆGradioå¯åŠ¨æ—¶çš„å·¥ä½œç›®å½•ï¼‰ï¼Œç¡®ä¿Gradioå¯ä»¥è®¿é—®
                # ä½¿ç”¨os.getcwd()è·å–Gradioçš„å®é™…å·¥ä½œç›®å½•
                current_work_dir = os.getcwd()
                # åœ¨å½“å‰å·¥ä½œç›®å½•ä¸‹åˆ›å»ºexportså­ç›®å½•ç”¨äºä¸´æ—¶å¯¼å‡ºæ–‡ä»¶
                exports_dir = os.path.join(current_work_dir, "exports")
                os.makedirs(exports_dir, exist_ok=True)
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                
                if format_type == "word":
                    filename = f"cluster_report_{timestamp}.docx"
                    output_path = os.path.join(exports_dir, filename)
                    export_to_word(last_agent_response, output_path)
                    status_msg = f"âœ… Wordæ–‡æ¡£å·²ç”Ÿæˆï¼Œè¯·ç‚¹å‡»ä¸‹æ–¹ä¸‹è½½é“¾æ¥"
                    # è¿”å›ç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºå·¥ä½œç›®å½•ï¼‰ï¼ŒGradioæ›´å®¹æ˜“å¤„ç†
                    abs_path = os.path.abspath(output_path)
                    rel_path = os.path.relpath(output_path, current_work_dir)
                    print(f"[DEBUG] å¯¼å‡ºWordæ–‡ä»¶ - ç»å¯¹è·¯å¾„: {abs_path}")
                    print(f"[DEBUG] å¯¼å‡ºWordæ–‡ä»¶ - ç›¸å¯¹è·¯å¾„: {rel_path}")
                    print(f"[DEBUG] æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(abs_path)}")
                    print(f"[DEBUG] æ–‡ä»¶å¤§å°: {os.path.getsize(abs_path) if os.path.exists(abs_path) else 'N/A'} bytes")
                    # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ŒGradioå¯ä»¥æ›´å¥½åœ°å¤„ç†
                    return rel_path, status_msg
                else:  # pdf
                    filename = f"cluster_report_{timestamp}.pdf"
                    output_path = os.path.join(exports_dir, filename)
                    export_to_pdf(last_agent_response, output_path)
                    status_msg = f"âœ… PDFæ–‡æ¡£å·²ç”Ÿæˆï¼Œè¯·ç‚¹å‡»ä¸‹æ–¹ä¸‹è½½é“¾æ¥"
                    # è¿”å›ç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºå·¥ä½œç›®å½•ï¼‰ï¼ŒGradioæ›´å®¹æ˜“å¤„ç†
                    abs_path = os.path.abspath(output_path)
                    rel_path = os.path.relpath(output_path, current_work_dir)
                    print(f"[DEBUG] å¯¼å‡ºPDFæ–‡ä»¶ - ç»å¯¹è·¯å¾„: {abs_path}")
                    print(f"[DEBUG] å¯¼å‡ºPDFæ–‡ä»¶ - ç›¸å¯¹è·¯å¾„: {rel_path}")
                    print(f"[DEBUG] æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(abs_path)}")
                    print(f"[DEBUG] æ–‡ä»¶å¤§å°: {os.path.getsize(abs_path) if os.path.exists(abs_path) else 'N/A'} bytes")
                    # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ŒGradioå¯ä»¥æ›´å¥½åœ°å¤„ç†
                    return rel_path, status_msg
            except ImportError as e:
                if "docx" in str(e) or "python-docx" in str(e):
                    return None, "âŒ å¯¼å‡ºWordå¤±è´¥: éœ€è¦å®‰è£… python-docx (pip install python-docx)"
                elif "reportlab" in str(e):
                    return None, "âŒ å¯¼å‡ºPDFå¤±è´¥: éœ€è¦å®‰è£… reportlab (pip install reportlab)"
                else:
                    return None, f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}"
            except Exception as e:
                return None, f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}"
        
        msg.submit(respond, [msg, chatbot, model_selector], [chatbot, msg])
        submit_btn.click(respond, [msg, chatbot, model_selector], [chatbot, msg])
        clear_btn.click(lambda: ([], ""), None, [chatbot, msg])
        
        # ç»‘å®šå¯¼å‡ºæŒ‰é’®ï¼ˆåŒæ—¶æ›´æ–°æ–‡ä»¶ä¸‹è½½å’ŒçŠ¶æ€æ¶ˆæ¯ï¼‰
        # ä½¿ç”¨JavaScriptå®ç°è‡ªåŠ¨ä¸‹è½½
        export_word_btn.click(
            fn=lambda: export_document("word"),
            inputs=None,
            outputs=[export_file, export_status],
            js="""
            (file, status) => {
                if (file) {
                    setTimeout(() => {
                        // æŸ¥æ‰¾æ–‡ä»¶ä¸‹è½½é“¾æ¥å¹¶è‡ªåŠ¨ç‚¹å‡»
                        const fileLinks = document.querySelectorAll('a[href*="cluster_report"]');
                        if (fileLinks.length > 0) {
                            fileLinks[fileLinks.length - 1].click();
                        } else {
                            // å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥åˆ›å»ºä¸‹è½½é“¾æ¥
                            const link = document.createElement('a');
                            link.href = file;
                            link.download = file.split('/').pop() || 'cluster_report.docx';
                            link.style.display = 'none';
                            document.body.appendChild(link);
                            link.click();
                            setTimeout(() => document.body.removeChild(link), 100);
                        }
                    }, 500);
                }
                return [file, status];
            }
            """
        )
        export_pdf_btn.click(
            fn=lambda: export_document("pdf"),
            inputs=None,
            outputs=[export_file, export_status],
            js="""
            (file, status) => {
                if (file) {
                    setTimeout(() => {
                        // æŸ¥æ‰¾æ–‡ä»¶ä¸‹è½½é“¾æ¥å¹¶è‡ªåŠ¨ç‚¹å‡»
                        const fileLinks = document.querySelectorAll('a[href*="cluster_report"]');
                        if (fileLinks.length > 0) {
                            fileLinks[fileLinks.length - 1].click();
                        } else {
                            // å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥åˆ›å»ºä¸‹è½½é“¾æ¥
                            const link = document.createElement('a');
                            link.href = file;
                            link.download = file.split('/').pop() || 'cluster_report.pdf';
                            link.style.display = 'none';
                            document.body.appendChild(link);
                            link.click();
                            setTimeout(() => document.body.removeChild(link), 100);
                        }
                    }, 500);
                }
                return [file, status];
            }
            """
        )
        
        # é¡µé¢åŠ è½½æ—¶ç«‹å³æ›´æ–°ä¸€æ¬¡
        demo.load(
            fn=update_monitoring_display,
            inputs=None,
            outputs=monitoring_html
        )
        
        # æ³¨æ„ï¼šæŸäº› Gradio ç‰ˆæœ¬ä¸æ”¯æŒå®šæ—¶è‡ªåŠ¨æ›´æ–°
        # å¦‚æœéœ€è¦å®šæ—¶æ›´æ–°ï¼Œå¯ä»¥ï¼š
        # 1. ä½¿ç”¨æ‰‹åŠ¨åˆ·æ–°æŒ‰é’®ï¼ˆå·²å®ç°ï¼‰
        # 2. æˆ–è€…å‡çº§ Gradio åˆ°æ”¯æŒå®šæ—¶æ›´æ–°çš„ç‰ˆæœ¬
        # 3. æˆ–è€…ä½¿ç”¨ JavaScript åœ¨å‰ç«¯å®ç°å®šæ—¶åˆ·æ–°
    
    return demo


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("HDFS é›†ç¾¤ç›‘æ§ Agent - Gradio Web ç•Œé¢ (LangChain)")
    print("=" * 60)
    print()
    print("[INFO] ä½¿ç”¨ LangChain Agentï¼ˆè‡ªä¸»å·¥å…·è°ƒç”¨ï¼‰")
    print("[INFO] æ¨¡å¼: vLLMï¼ˆQwen3-8Bï¼‰")
    print()
    print("[æç¤º] vLLM é…ç½®ï¼š")
    print("[æç¤º]   - æœåŠ¡åœ°å€: http://localhost:8000/v1")
    print("[æç¤º]   - æ¨¡å‹è·¯å¾„: /media/hnu/LLM/hnu/LLM/Qwen3-8B")
    print()
    print("[æç¤º] è¯·ç¡®ä¿ vLLM æœåŠ¡å·²å¯åŠ¨")
    print("-" * 60)
    print()
    print("[INFO] æ­£åœ¨é¢„åŠ è½½ Agent...")
    print("[æç¤º] è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    print("-" * 60)
    
    # åœ¨å¯åŠ¨æ—¶é¢„åŠ è½½ Agentï¼ˆä½¿ç”¨é»˜è®¤æ¨¡å‹ qwen-8bï¼‰
    try:
        init_agent("qwen-8b")
        print("[INFO] Agent é¢„åŠ è½½å®Œæˆï¼ˆé»˜è®¤æ¨¡å‹: Qwen-8Bï¼‰ï¼")
    except Exception as e:
        print(f"[ERROR] Agent é¢„åŠ è½½å¤±è´¥: {e}")
        print()
        print("[é”™è¯¯] æ— æ³•å¯åŠ¨ Agentï¼Œè¯·æ£€æŸ¥ï¼š")
        print("  1. vLLM æœåŠ¡æ˜¯å¦å·²å¯åŠ¨")
        print("  2. æœåŠ¡åœ°å€æ˜¯å¦æ­£ç¡®")
        print("  3. æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®")
        print()
        print("[æç¤º] å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤æ£€æŸ¥ vLLM æœåŠ¡ï¼š")
        print("  curl http://10.157.197.76:8001/health")
        print()
        print("[æç¤º] å¦‚æœ vLLM æœåŠ¡ä¸å¯ç”¨ï¼Œå¯ä»¥åœ¨ç•Œé¢ä¸­åˆ‡æ¢åˆ°å…¶ä»–æ¨¡å‹ï¼ˆGPT-4o æˆ– DeepSeek-R1ï¼‰")
        print()
        # ä¸é€€å‡ºï¼Œå…è®¸ç”¨æˆ·åˆ‡æ¢åˆ°å…¶ä»–æ¨¡å‹
        # sys.exit(1)
    
    print()
    print("[INFO] æ­£åœ¨å¯åŠ¨ Gradio ç•Œé¢...")
    print("[INFO] ç•Œé¢å¯åŠ¨åï¼Œè¯·åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æ˜¾ç¤ºçš„ URL")
    print("-" * 60)
    print()
    
    # å®šä¹‰ä¼˜é›…å…³é—­å‡½æ•°
    def graceful_shutdown(signum=None, frame=None):
        """ä¼˜é›…å…³é—­ Gradio æœåŠ¡å™¨"""
        global demo_instance, _shutting_down
        
        # é˜²æ­¢é‡å¤è°ƒç”¨
        if _shutting_down:
            # å¦‚æœå·²ç»åœ¨å…³é—­è¿‡ç¨‹ä¸­ï¼Œç›´æ¥å¼ºåˆ¶é€€å‡º
            os._exit(0)
            return
        
        _shutting_down = True
        print("\n[INFO] æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­æœåŠ¡å™¨...")
        
        # åœ¨æ–°çº¿ç¨‹ä¸­å…³é—­ï¼Œé¿å…é˜»å¡ä¿¡å·å¤„ç†
        import threading
        def close_demo():
            if demo_instance is not None:
                try:
                    demo_instance.close()
                    print("[INFO] Gradio æœåŠ¡å™¨å·²å…³é—­")
                except Exception as e:
                    print(f"[WARNING] å…³é—­æœåŠ¡å™¨æ—¶å‡ºé”™: {e}")
            # çŸ­æš‚å»¶è¿Ÿåå¼ºåˆ¶é€€å‡º
            import time
            time.sleep(0.1)
            os._exit(0)
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œå…³é—­ï¼Œä¸»çº¿ç¨‹ç«‹å³é€€å‡º
        close_thread = threading.Thread(target=close_demo, daemon=True)
        close_thread.start()
        
        # ä¸»çº¿ç¨‹ç«‹å³é€€å‡ºï¼ˆä½¿ç”¨ os._exit å¼ºåˆ¶ç»ˆæ­¢æ‰€æœ‰çº¿ç¨‹ï¼‰
        os._exit(0)
    
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨ï¼ˆSIGINT = Ctrl+Cï¼‰
    signal.signal(signal.SIGINT, graceful_shutdown)
    if sys.platform != "win32":
        signal.signal(signal.SIGTERM, graceful_shutdown)
    
    # æ³¨æ„ï¼šä¸æ³¨å†Œ atexitï¼Œå› ä¸º atexit ä¼šåœ¨ sys.exit() æ—¶è°ƒç”¨ï¼Œå¯èƒ½å¯¼è‡´é‡å¤å…³é—­
    # å¦‚æœéœ€è¦ï¼Œå¯ä»¥åœ¨ atexit ä¸­åªåšæ¸…ç†ï¼Œä¸åšé€€å‡º
    
    try:
        # åˆ›å»ºç•Œé¢
        demo = create_gradio_interface()
        global demo_instance
        demo_instance = demo
        
        # å¯åŠ¨ç•Œé¢
        # share=False: ä¸åˆ›å»ºå…¬å…±é“¾æ¥ï¼ˆä»…æœ¬åœ°è®¿é—®ï¼‰
        # server_name="0.0.0.0": å…è®¸å±€åŸŸç½‘è®¿é—®ï¼ˆå¯é€‰ï¼‰
        # server_port=7860: æŒ‡å®šç«¯å£ï¼ˆå¯é€‰ï¼‰
        # è·å–exportsç›®å½•çš„ç»å¯¹è·¯å¾„ï¼Œæ·»åŠ åˆ°allowed_paths
        import os
        current_work_dir = os.getcwd()
        exports_dir = os.path.join(current_work_dir, "exports")
        exports_dir_abs = os.path.abspath(exports_dir)
        os.makedirs(exports_dir_abs, exist_ok=True)
        
        print(f"[DEBUG] Gradioå·¥ä½œç›®å½•: {current_work_dir}")
        print(f"[DEBUG] Exportsç›®å½•: {exports_dir_abs}")
        
        # å¯åŠ¨ç•Œé¢
        demo.launch(
            share=False,  # è®¾ç½®ä¸º True å¯ä»¥åˆ›å»ºå…¬å…±é“¾æ¥
            server_name="127.0.0.1",  # æ”¹ä¸º127.0.0.1é¿å…ç½‘ç»œé—®é¢˜
            server_port=7860,  # ç«¯å£å·
            show_error=True,  # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            allowed_paths=[exports_dir_abs, current_work_dir]  # å…è®¸è®¿é—®exportsç›®å½•å’Œå·¥ä½œç›®å½•
        )
    except KeyboardInterrupt:
        graceful_shutdown()
    except Exception as e:
        print(f"\n[ERROR] å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        graceful_shutdown()
        sys.exit(1)


if __name__ == "__main__":
    main()

