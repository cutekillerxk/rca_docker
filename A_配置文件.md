æ˜ç™½äº†ï¼Œä½ ç°åœ¨è¦è¿›å…¥ **Hadoop é›†ç¾¤é…ç½®é˜¶æ®µ**ï¼Œä¹Ÿå°±æ˜¯åœ¨æ¯ä¸ªå®¹å™¨å†…ç¼–è¾‘ Hadoop çš„é…ç½®æ–‡ä»¶ï¼Œè®© NameNode å’Œ DataNode èƒ½äº’ç›¸è¯†åˆ«å¹¶æ­£å¸¸å·¥ä½œã€‚ä¸‹é¢æˆ‘ç»™ä½ ä¸€ä¸ª **é€æ­¥æ“ä½œæŒ‡å—**ï¼Œè§£é‡Šæ¯ä¸ªé…ç½®æ–‡ä»¶çš„ä½œç”¨å’Œå¦‚ä½•è®¾ç½®ã€‚

---

# **å‰æ**

* ä½ å·²ç»åœ¨æ¯ä¸ªå®¹å™¨å®‰è£…äº† **Java + SSH + Hadoop**ã€‚
* è‡ªå®šä¹‰ç½‘ç»œ `hadoop-net` å·²åˆ›å»ºï¼Œå¹¶ä¸”å®¹å™¨éƒ½åœ¨è¿™ä¸ªç½‘ç»œé‡Œã€‚
* å®¹å™¨åç§°ï¼š

  * `hadoop-namenode`
  * `hadoop-datanode1`
  * `hadoop-datanode2`

---

# **1ï¸âƒ£ core-site.xml**

* **ä½ç½®**ï¼š`$HADOOP_HOME/etc/hadoop/core-site.xml`
* **ä½œç”¨**ï¼šè®¾ç½® Hadoop çš„æ ¸å¿ƒé…ç½®ï¼ŒåŒ…æ‹¬ HDFS çš„åœ°å€ã€‚
* **æ“ä½œ**ï¼ˆNameNode å®¹å™¨å†…ï¼‰ï¼š

```bash
cd $HADOOP_HOME/etc/hadoop
vim core-site.xml
```

* **ç¤ºä¾‹é…ç½®**ï¼š

```xml
<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://namenode:9000</value>
  </property>
</configuration>


```

<configuration>

  <!-- Hadoop é»˜è®¤ NameNode åœ°å€ï¼ˆç«¯å£æ”¹ä¸º 9000 ä¹Ÿå¯ä»¥ï¼‰ -->
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://namenode:9000</value>
  </property>

  <!-- NameNode RPC åœ°å€ï¼Œå¿…é¡»ç›‘å¬ 0.0.0.0ï¼Œå¦åˆ™å®¹å™¨å¤–æ— æ³•è®¿é—® -->
  <property>
    <name>dfs.namenode.rpc-address</name>
    <value>0.0.0.0:9000</value>
  </property>

  <!-- NameNode WebUI åœ°å€ï¼š9870ï¼ˆå¿…é¡»ç›‘å¬ 0.0.0.0ï¼‰ -->
  <property>
    <name>dfs.namenode.http-address</name>
    <value>0.0.0.0:9870</value>
  </property>

  <!-- HDFS é™æ€ç”¨æˆ·ï¼ˆé¿å…æƒé™é—®é¢˜ï¼‰ -->
  <property>
    <name>hadoop.http.staticuser.user</name>
    <value>root</value>
  </property>

</configuration>


* **è¯´æ˜**ï¼š

  * `fs.defaultFS`ï¼šHDFS çš„é»˜è®¤æ–‡ä»¶ç³»ç»Ÿ URI
  * `namenode`ï¼šå®¹å™¨åï¼Œä¹Ÿå°±æ˜¯ NameNode çš„ hostnameï¼ˆDocker ç½‘ç»œè§£æï¼‰
  * `9000`ï¼šHDFS RPC ç«¯å£

---

# **2ï¸âƒ£ hdfs-site.xml**

* **ä½œç”¨**ï¼šè®¾ç½® HDFS ç›¸å…³ç›®å½•ã€DataNode å­˜å‚¨ç­‰
* **æ“ä½œ**ï¼š

```bash
vim hdfs-site.xml
```

* **ç¤ºä¾‹é…ç½®**ï¼š

```xml
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>2</value>
  </property>

  <property>
    <name>dfs.namenode.name.dir</name>
    <value>/usr/local/hadoop/hdfs/namenode</value>
  </property>

  <property>
    <name>dfs.datanode.data.dir</name>
    <value>/usr/local/hadoop/hdfs/datanode</value>
  </property>
</configuration>
```

* **è¯´æ˜**ï¼š

  * `dfs.replication`ï¼šHDFS å‰¯æœ¬æ•°é‡ï¼ˆæ ¹æ® DataNode æ•°é‡è®¾ç½®ï¼Œä¸€èˆ¬ â‰¤ DataNode æ•°ï¼‰
  * `dfs.namenode.name.dir`ï¼šNameNode å­˜å‚¨ç›®å½•
  * `dfs.datanode.data.dir`ï¼šDataNode å­˜å‚¨ç›®å½•

> æç¤ºï¼šåœ¨æ¯ä¸ªèŠ‚ç‚¹å®¹å™¨é‡Œè¦ä¿è¯è¿™äº›ç›®å½•å­˜åœ¨

```bash
mkdir -p /usr/local/hadoop/hdfs/namenode
mkdir -p /usr/local/hadoop/hdfs/datanode
```

---

# **3ï¸âƒ£ mapred-site.xml**

* **ä½œç”¨**ï¼šMapReduce é…ç½®
* **æ“ä½œ**ï¼š

```bash
cp mapred-site.xml.template mapred-site.xml
vim mapred-site.xml
```

* **ç¤ºä¾‹é…ç½®**ï¼š

```xml
<configuration>
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>
</configuration>
```

* **è¯´æ˜**ï¼š

  * `mapreduce.framework.name`ï¼šæŒ‡å®šä½¿ç”¨ YARN ä½œä¸ºèµ„æºç®¡ç†æ¡†æ¶

---

# **4ï¸âƒ£ yarn-site.xml**

* **ä½œç”¨**ï¼šYARN é…ç½®ï¼ŒåŒ…æ‹¬ ResourceManager å’Œ NodeManager
* **æ“ä½œ**ï¼š

```bash
vim yarn-site.xml
```

* **ç¤ºä¾‹é…ç½®**ï¼š

```xml
<configuration>
  <property>
    <name>yarn.resourcemanager.hostname</name>
    <value>namenode</value>
  </property>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>
</configuration>
```

* **è¯´æ˜**ï¼š

  * `yarn.resourcemanager.hostname`ï¼šæŒ‡å®š ResourceManager ä¸»æœºï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ NameNode å®¹å™¨
  * `mapreduce_shuffle`ï¼šYARN MapReduce shuffle æœåŠ¡

---

# **5ï¸âƒ£ workers æ–‡ä»¶**

* **ä½ç½®**ï¼š`$HADOOP_HOME/etc/hadoop/workers`
* **ä½œç”¨**ï¼šåˆ—å‡ºæ‰€æœ‰ DataNode èŠ‚ç‚¹
* **æ“ä½œ**ï¼š

```bash
vim workers
```

* **å†…å®¹ç¤ºä¾‹**ï¼š

```
namenode
datanode1
datanode2
```

> æ³¨æ„ï¼šå¡«å†™å®¹å™¨ hostnameï¼ŒHadoop å¯åŠ¨ DFS/Datanode æ—¶ä¼šè¯»å– workers æ–‡ä»¶ã€‚

---

# **æ“ä½œæ€»ç»“**

1. **NameNode å®¹å™¨**ï¼š

   * ç¼–è¾‘ï¼š`core-site.xml`, `hdfs-site.xml`, `mapred-site.xml`, `yarn-site.xml`
   * ç¼–è¾‘ workers æ–‡ä»¶ï¼Œåˆ—å‡º DataNode å®¹å™¨å
   * åˆ›å»º HDFS ç›®å½•ï¼š

     ```bash
     mkdir -p /usr/local/hadoop/hdfs/namenode
     mkdir -p /usr/local/hadoop/hdfs/datanode
     ```

2. **DataNode å®¹å™¨**ï¼š

   * ç¼–è¾‘ï¼š`core-site.xml`, `hdfs-site.xml`, `mapred-site.xml`, `yarn-site.xml`ï¼ˆåŒ NameNodeï¼Œé™¤ `dfs.namenode.name.dir` å¯ä¸ç”¨åˆ›å»ºï¼‰
   * åˆ›å»º DataNode å­˜å‚¨ç›®å½•ï¼š

     ```bash
     mkdir -p /usr/local/hadoop/hdfs/datanode
     ```

3. **ä¿æŒç½‘ç»œé€šä¿¡æ­£å¸¸**ï¼š

   * NameNode å¯ä»¥é€šè¿‡ `namenode` å®¹å™¨åè®¿é—®
   * DataNode å¯ä»¥é€šè¿‡ `namenode` å®¹å™¨åè®¿é—® NameNode

---

ğŸ’¡ **æç¤º**ï¼š

* ç¼–è¾‘é…ç½®æ—¶ï¼Œæ‰€æœ‰å®¹å™¨çš„ `$HADOOP_HOME` è·¯å¾„è¦ä¸€è‡´
* é…ç½®æ–‡ä»¶ä¸­ä½¿ç”¨å®¹å™¨åä½œä¸º hostnameï¼Œè¿™æ · Docker ç½‘ç»œå¯ä»¥è§£æ
* å®Œæˆé…ç½®åï¼Œå¯ä»¥æ‰§è¡Œ **NameNode æ ¼å¼åŒ–** å¹¶å¯åŠ¨ HDFS

---

å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘å¯ä»¥å¸®ä½ å†™ä¸€ä¸ª **å®Œæ•´çš„ç¤ºä¾‹é…ç½®æ–‡ä»¶é›†ï¼ˆcore-siteã€hdfs-siteã€yarn-siteã€mapred-siteã€workersï¼‰**ï¼Œä½ ç›´æ¥å¤åˆ¶åˆ°å®¹å™¨ä¸­å°±èƒ½ç”¨ï¼Œä¿è¯ NameNode + 2 ä¸ª DataNode çš„å°é›†ç¾¤å¯ç”¨ã€‚

ä½ å¸Œæœ›æˆ‘ç›´æ¥ç»™è¿™ä¸ªå®Œæ•´é…ç½®å—ï¼Ÿ
PermitRootLogin yes
PasswordAuthentication yes
service ssh restart
